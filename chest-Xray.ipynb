{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839},{"sourceId":14152500,"sourceType":"datasetVersion","datasetId":9020181},{"sourceId":14435144,"sourceType":"datasetVersion","datasetId":9220381},{"sourceId":684182,"sourceType":"modelInstanceVersion","modelInstanceId":519131,"modelId":533603},{"sourceId":711014,"sourceType":"modelInstanceVersion","modelInstanceId":540182,"modelId":553372}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"id":"OfdoJUXgk0UC","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:23.993613Z","iopub.execute_input":"2026-01-08T13:00:23.993895Z","iopub.status.idle":"2026-01-08T13:00:24.999898Z","shell.execute_reply.started":"2026-01-08T13:00:23.993872Z","shell.execute_reply":"2026-01-08T13:00:24.999148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pickle\n\ndef save_graph_rag_system(\n    model,\n    proto_matrix,\n    adjacency,\n    diseases,\n    graph,\n    save_dir=\"saved_graph_rag\"\n):\n    import os\n    os.makedirs(save_dir, exist_ok=True)\n\n    # 1️⃣ Save model\n    torch.save(\n        model.state_dict(),\n        f\"{save_dir}/cnn_weights.pth\"\n    )\n\n    # 2️⃣ Save core tensors\n    torch.save({\n        \"proto_matrix\": proto_matrix.cpu(),\n        \"adjacency\": adjacency.cpu(),\n        \"diseases\": diseases\n    }, f\"{save_dir}/graph_core.pth\")\n\n    # 3️⃣ Save graph index\n    with open(f\"{save_dir}/graph_index.pkl\", \"wb\") as f:\n        pickle.dump(graph, f)\n\n    # 4️⃣ Save preprocessing config\n    preprocess_cfg = {\n        \"image_size\": 224,\n        \"mean\": [0.485, 0.456, 0.406],\n        \"std\": [0.229, 0.224, 0.225]\n    }\n\n    with open(f\"{save_dir}/preprocess.pkl\", \"wb\") as f:\n        pickle.dump(preprocess_cfg, f)\n\n    print(\"✅ Graph-RAG system saved successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:25.000934Z","iopub.execute_input":"2026-01-08T13:00:25.001226Z","iopub.status.idle":"2026-01-08T13:00:28.605378Z","shell.execute_reply.started":"2026-01-08T13:00:25.001207Z","shell.execute_reply":"2026-01-08T13:00:28.604728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pickle\n\ndef load_graph_rag_system(\n    model,\n    device,\n    save_dir=\"saved_graph_rag\"\n):\n    # 1️⃣ Load model weights\n    model.load_state_dict(\n        torch.load(f\"{save_dir}/cnn_weights.pth\", map_location=device)\n    )\n    model.eval()\n\n    # 2️⃣ Load core graph tensors\n    core = torch.load(\n        f\"{save_dir}/graph_core.pth\",\n        map_location=device\n    )\n\n    proto_matrix = core[\"proto_matrix\"].to(device)\n    adjacency = core[\"adjacency\"].to(device)\n    diseases = core[\"diseases\"]\n\n    # 3️⃣ Load graph index\n    with open(f\"{save_dir}/graph_index.pkl\", \"rb\") as f:\n        graph = pickle.load(f)\n\n    # 4️⃣ Load preprocessing config\n    with open(f\"{save_dir}/preprocess.pkl\", \"rb\") as f:\n        preprocess_cfg = pickle.load(f)\n\n    print(\"✅ Graph-RAG system loaded successfully\")\n\n    return {\n        \"model\": model,\n        \"proto_matrix\": proto_matrix,\n        \"adjacency\": adjacency,\n        \"diseases\": diseases,\n        \"graph\": graph,\n        \"preprocess\": preprocess_cfg\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:28.606096Z","iopub.execute_input":"2026-01-08T13:00:28.606579Z","iopub.status.idle":"2026-01-08T13:00:28.612272Z","shell.execute_reply.started":"2026-01-08T13:00:28.606539Z","shell.execute_reply":"2026-01-08T13:00:28.611515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Make sure model is in eval mode\n# model.eval()\n\n# # Call the save function\n# save_graph_rag_system(\n#     model=model,\n#     proto_matrix=proto_matrix,\n#     adjacency=A,\n#     diseases=diseases,\n#     graph=graph,\n#     save_dir=\"saved_graph_rag\"\n# )\n\n\n\n# #Save and Load\n\n\n\n\n\n\n\n\n# # \n# # Recreate model architecture\n# model = DenseNet121_new(num_classes=14).to(device)\n\n# system = load_graph_rag_system(model, device)\n\n# model = system[\"model\"]\n# proto_matrix = system[\"proto_matrix\"]\n# graph = system[\"graph\"]\n# diseases = system[\"diseases\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:28.613889Z","iopub.execute_input":"2026-01-08T13:00:28.614155Z","iopub.status.idle":"2026-01-08T13:00:28.626330Z","shell.execute_reply.started":"2026-01-08T13:00:28.614138Z","shell.execute_reply":"2026-01-08T13:00:28.625679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\n# path = kagglehub.dataset_download(\"nih-chest-xrays/data\")\n\n# print(\"Path to dataset files:\", path)\npath='/kaggle/input/data'","metadata":{"id":"cLJG5404ifSO","outputId":"4e94d1ab-43b6-4b2c-99ca-cd5bf971dbec","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:28.626982Z","iopub.execute_input":"2026-01-08T13:00:28.627206Z","iopub.status.idle":"2026-01-08T13:00:28.764517Z","shell.execute_reply.started":"2026-01-08T13:00:28.627190Z","shell.execute_reply":"2026-01-08T13:00:28.763929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Path to dataset files:\", path)","metadata":{"id":"fP2hE9EVjDUt","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:28.765241Z","iopub.execute_input":"2026-01-08T13:00:28.765487Z","iopub.status.idle":"2026-01-08T13:00:28.769270Z","shell.execute_reply.started":"2026-01-08T13:00:28.765465Z","shell.execute_reply":"2026-01-08T13:00:28.768539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfor root, dirs, files in os.walk(path, topdown=True):\n    print(root, dirs, files)\n    break\n","metadata":{"id":"AmAFtPs-kWjf","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:28.770025Z","iopub.execute_input":"2026-01-08T13:00:28.770350Z","iopub.status.idle":"2026-01-08T13:00:28.788371Z","shell.execute_reply.started":"2026-01-08T13:00:28.770312Z","shell.execute_reply":"2026-01-08T13:00:28.787750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbox_csv = os.path.join(path, 'BBox_List_2017.csv')\ndata_csv = os.path.join(path, 'Data_Entry_2017.csv')","metadata":{"id":"hmaohnH-kc6x","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:28.788984Z","iopub.execute_input":"2026-01-08T13:00:28.789235Z","iopub.status.idle":"2026-01-08T13:00:28.792787Z","shell.execute_reply.started":"2026-01-08T13:00:28.789217Z","shell.execute_reply":"2026-01-08T13:00:28.791975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbox_pd=pd.read_csv(bbox_csv)\ndata_pd=pd.read_csv(data_csv)","metadata":{"id":"sIfgGF2zkvR9","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:28.793473Z","iopub.execute_input":"2026-01-08T13:00:28.793702Z","iopub.status.idle":"2026-01-08T13:00:29.061048Z","shell.execute_reply.started":"2026-01-08T13:00:28.793686Z","shell.execute_reply":"2026-01-08T13:00:29.060376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd.shape","metadata":{"id":"5Dyc6B1k0vAU","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:29.063743Z","iopub.execute_input":"2026-01-08T13:00:29.064005Z","iopub.status.idle":"2026-01-08T13:00:29.069774Z","shell.execute_reply.started":"2026-01-08T13:00:29.063985Z","shell.execute_reply":"2026-01-08T13:00:29.068968Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#data_csv is : 112120*12","metadata":{"id":"ojEjc7CGykkg"}},{"cell_type":"code","source":"data_pd.head()","metadata":{"id":"DUATZx3ek4rI","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:29.070625Z","iopub.execute_input":"2026-01-08T13:00:29.070858Z","iopub.status.idle":"2026-01-08T13:00:29.101215Z","shell.execute_reply.started":"2026-01-08T13:00:29.070831Z","shell.execute_reply":"2026-01-08T13:00:29.100589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimage_folders = []\nfor i in range(1, 13): # Loop from 1 to 12\n    folder_name = f'images_{i:03d}' # Format as images_001, images_002, ..., images_012\n    folder_path = os.path.join(path, folder_name)\n    image_folders.append(folder_path)\n\n# You can uncomment the following lines to print the paths and verify\n# for folder in image_folders:\n#     print(folder)","metadata":{"id":"coB-6ccik4Vj","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:29.101947Z","iopub.execute_input":"2026-01-08T13:00:29.102234Z","iopub.status.idle":"2026-01-08T13:00:29.106899Z","shell.execute_reply.started":"2026-01-08T13:00:29.102213Z","shell.execute_reply":"2026-01-08T13:00:29.106038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_folders[0]","metadata":{"id":"k-zhlU232KOC","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:29.107740Z","iopub.execute_input":"2026-01-08T13:00:29.108010Z","iopub.status.idle":"2026-01-08T13:00:29.117804Z","shell.execute_reply.started":"2026-01-08T13:00:29.107984Z","shell.execute_reply":"2026-01-08T13:00:29.117162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd.columns","metadata":{"id":"yVLGf8AunNZL","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:29.118449Z","iopub.execute_input":"2026-01-08T13:00:29.118760Z","iopub.status.idle":"2026-01-08T13:00:29.129572Z","shell.execute_reply.started":"2026-01-08T13:00:29.118733Z","shell.execute_reply":"2026-01-08T13:00:29.128974Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#The Path is the path of the .jpg file of that patient .\nHere view 1 is frontal and view 2 is lateral\n\nThe patient are in order number\n\nEach patient have different number of studies\n\nEach study has the image either frontal or lateral or both","metadata":{"id":"3TBjsMv6ntur"}},{"cell_type":"code","source":"for i in range (0,12):\n  # Get the base folder name (e.g., 'images_001') for better readability in the output\n  folder_name_display = os.path.basename(image_folders[i])\n  print(f\"  Number of files in {folder_name_display} is {len(os.listdir(os.path.join(image_folders[i],'images')))}\")","metadata":{"id":"3mpGLaWjvVDx","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:29.130178Z","iopub.execute_input":"2026-01-08T13:00:29.130399Z","iopub.status.idle":"2026-01-08T13:00:30.335887Z","shell.execute_reply.started":"2026-01-08T13:00:29.130383Z","shell.execute_reply":"2026-01-08T13:00:30.335367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Patient Gender\"].info()","metadata":{"id":"RRWEUmQp5OIf","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.336527Z","iopub.execute_input":"2026-01-08T13:00:30.336776Z","iopub.status.idle":"2026-01-08T13:00:30.358061Z","shell.execute_reply.started":"2026-01-08T13:00:30.336757Z","shell.execute_reply":"2026-01-08T13:00:30.357355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Patient Gender\"].value_counts()","metadata":{"id":"5_4LSqPqx-Mv","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.358698Z","iopub.execute_input":"2026-01-08T13:00:30.358895Z","iopub.status.idle":"2026-01-08T13:00:30.390129Z","shell.execute_reply.started":"2026-01-08T13:00:30.358880Z","shell.execute_reply":"2026-01-08T13:00:30.389523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Patient Age\"]","metadata":{"id":"4gIZnh9dyOOk","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.390918Z","iopub.execute_input":"2026-01-08T13:00:30.391705Z","iopub.status.idle":"2026-01-08T13:00:30.401879Z","shell.execute_reply.started":"2026-01-08T13:00:30.391686Z","shell.execute_reply":"2026-01-08T13:00:30.401188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Patient Age\"].info()","metadata":{"id":"dM19iTh35rnG","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.403257Z","iopub.execute_input":"2026-01-08T13:00:30.403529Z","iopub.status.idle":"2026-01-08T13:00:30.415246Z","shell.execute_reply.started":"2026-01-08T13:00:30.403512Z","shell.execute_reply":"2026-01-08T13:00:30.414560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Patient Age\"].value_counts()","metadata":{"id":"E149zKAb5uav","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.416156Z","iopub.execute_input":"2026-01-08T13:00:30.416445Z","iopub.status.idle":"2026-01-08T13:00:30.425961Z","shell.execute_reply.started":"2026-01-08T13:00:30.416419Z","shell.execute_reply":"2026-01-08T13:00:30.425191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[data_pd[\"Patient Age\"]>100]","metadata":{"id":"LYBowRDc56ep","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.426598Z","iopub.execute_input":"2026-01-08T13:00:30.426830Z","iopub.status.idle":"2026-01-08T13:00:30.446967Z","shell.execute_reply.started":"2026-01-08T13:00:30.426812Z","shell.execute_reply":"2026-01-08T13:00:30.446367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Patient Age\"].describe()","metadata":{"id":"jVe4HUE05yRW","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.447702Z","iopub.execute_input":"2026-01-08T13:00:30.447954Z","iopub.status.idle":"2026-01-08T13:00:30.459672Z","shell.execute_reply.started":"2026-01-08T13:00:30.447938Z","shell.execute_reply":"2026-01-08T13:00:30.458934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd = data_pd.copy()\ndata_clean_pd['Patient Age'] = data_clean_pd['Patient Age'].clip(upper=120)\n","metadata":{"id":"YoC7v1zhBCC1","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.460397Z","iopub.execute_input":"2026-01-08T13:00:30.460630Z","iopub.status.idle":"2026-01-08T13:00:30.469501Z","shell.execute_reply.started":"2026-01-08T13:00:30.460613Z","shell.execute_reply":"2026-01-08T13:00:30.468877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd['Patient Age']","metadata":{"id":"7tEVTqrzSRBj","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.470287Z","iopub.execute_input":"2026-01-08T13:00:30.470587Z","iopub.status.idle":"2026-01-08T13:00:30.476694Z","shell.execute_reply.started":"2026-01-08T13:00:30.470564Z","shell.execute_reply":"2026-01-08T13:00:30.476083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd['Patient Age'].max()","metadata":{"id":"Ai6z6FMxCxjF","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.477417Z","iopub.execute_input":"2026-01-08T13:00:30.477967Z","iopub.status.idle":"2026-01-08T13:00:30.488524Z","shell.execute_reply.started":"2026-01-08T13:00:30.477949Z","shell.execute_reply":"2026-01-08T13:00:30.487929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"age_stats = data_clean_pd['Patient Age'].describe()\nprint(age_stats)\n","metadata":{"id":"6qIZzutWyiVM","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.489210Z","iopub.execute_input":"2026-01-08T13:00:30.489516Z","iopub.status.idle":"2026-01-08T13:00:30.503714Z","shell.execute_reply.started":"2026-01-08T13:00:30.489493Z","shell.execute_reply":"2026-01-08T13:00:30.503038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd[data_clean_pd['Patient Age']>=100]","metadata":{"id":"bek7SbZpWmue","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.504877Z","iopub.execute_input":"2026-01-08T13:00:30.505152Z","iopub.status.idle":"2026-01-08T13:00:30.518179Z","shell.execute_reply.started":"2026-01-08T13:00:30.505135Z","shell.execute_reply":"2026-01-08T13:00:30.517471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from numpy._core.multiarray import concatenate\n# result_horizontal = pd.concat([df1, df2], axis=1)\ndata_clean_pd = pd.concat([data_clean_pd,pd.DataFrame(columns=['age_group'])],axis=1)","metadata":{"id":"b-Roxk6v06pS","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.523060Z","iopub.execute_input":"2026-01-08T13:00:30.523444Z","iopub.status.idle":"2026-01-08T13:00:30.544251Z","shell.execute_reply.started":"2026-01-08T13:00:30.523427Z","shell.execute_reply":"2026-01-08T13:00:30.543246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd","metadata":{"id":"EzLvUIiJRzD4","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.545217Z","iopub.execute_input":"2026-01-08T13:00:30.545616Z","iopub.status.idle":"2026-01-08T13:00:30.558728Z","shell.execute_reply.started":"2026-01-08T13:00:30.545592Z","shell.execute_reply":"2026-01-08T13:00:30.558095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bins = [0, 18, 35, 60, 100,121]\nlabels = ['Youth', 'Adult', 'Middle Age', 'Senior',\"Very Senior\"]\n\n# Re-initialize data_clean_pd with Patient Age and apply clipping\n# data_clean_pd = data_pd.copy()\n# data_clean_pd['Patient Age'] = data_clean_pd['Patient Age'].clip(upper=120)\n\n# Create a new categorical column\n\ndata_clean_pd['age_group'] = pd.cut(data_clean_pd['Patient Age'], bins=bins, labels=labels, right=False)\n\n# View the frequency of each group\nage_group_counts = data_clean_pd['age_group'].value_counts()\nprint(age_group_counts)","metadata":{"id":"aLm3vEoR0KMT","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.559427Z","iopub.execute_input":"2026-01-08T13:00:30.559661Z","iopub.status.idle":"2026-01-08T13:00:30.577469Z","shell.execute_reply.started":"2026-01-08T13:00:30.559635Z","shell.execute_reply":"2026-01-08T13:00:30.576626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"View Position\"].describe()","metadata":{"id":"Ei3sRHTV1TOI","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.578296Z","iopub.execute_input":"2026-01-08T13:00:30.578553Z","iopub.status.idle":"2026-01-08T13:00:30.597338Z","shell.execute_reply.started":"2026-01-08T13:00:30.578532Z","shell.execute_reply":"2026-01-08T13:00:30.596697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Follow-up #\"]","metadata":{"id":"Oj2xLmDDXvKC","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.598198Z","iopub.execute_input":"2026-01-08T13:00:30.598522Z","iopub.status.idle":"2026-01-08T13:00:30.607168Z","shell.execute_reply.started":"2026-01-08T13:00:30.598502Z","shell.execute_reply":"2026-01-08T13:00:30.606522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Follow-up #\"].describe()","metadata":{"id":"_FOQrjaNXeUn","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.607932Z","iopub.execute_input":"2026-01-08T13:00:30.608281Z","iopub.status.idle":"2026-01-08T13:00:30.622715Z","shell.execute_reply.started":"2026-01-08T13:00:30.608258Z","shell.execute_reply":"2026-01-08T13:00:30.622161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd[\"Finding Labels\"]","metadata":{"id":"FgYjEMY3X-zS","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.623299Z","iopub.execute_input":"2026-01-08T13:00:30.623538Z","iopub.status.idle":"2026-01-08T13:00:30.629469Z","shell.execute_reply.started":"2026-01-08T13:00:30.623520Z","shell.execute_reply":"2026-01-08T13:00:30.628732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd['Finding Labels'].value_counts()","metadata":{"id":"FpTIsXp3YM-G","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.630125Z","iopub.execute_input":"2026-01-08T13:00:30.630371Z","iopub.status.idle":"2026-01-08T13:00:30.647522Z","shell.execute_reply.started":"2026-01-08T13:00:30.630350Z","shell.execute_reply":"2026-01-08T13:00:30.646929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pd['Finding Labels'].describe()","metadata":{"id":"uDoyI9LAYCjv","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.648230Z","iopub.execute_input":"2026-01-08T13:00:30.648503Z","iopub.status.idle":"2026-01-08T13:00:30.671098Z","shell.execute_reply.started":"2026-01-08T13:00:30.648487Z","shell.execute_reply":"2026-01-08T13:00:30.670363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"diseases = [\n\n\n            'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n    'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax',\n    'Consolidation', 'Edema', 'Emphysema',\n    'Fibrosis', 'Pleural_Thickening', 'Hernia'\n]\n","metadata":{"id":"HXZq_QzDcpW6","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.671883Z","iopub.execute_input":"2026-01-08T13:00:30.672090Z","iopub.status.idle":"2026-01-08T13:00:30.676105Z","shell.execute_reply.started":"2026-01-08T13:00:30.672065Z","shell.execute_reply":"2026-01-08T13:00:30.675415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-hot encode diseases\nfor d in diseases:\n    data_clean_pd[d] = data_clean_pd['Finding Labels'].str.contains(d).astype(int)\n\n# One-hot encode No Finding\ndata_clean_pd['No_Finding'] = (data_clean_pd['Finding Labels'] == 'No Finding').astype(int)\n\n# Ensure correctness: No Finding => all disease labels = 0\ndata_clean_pd.loc[data_clean_pd['No_Finding'] == 1, diseases] = 0\n","metadata":{"id":"p7mTz7Gwc80m","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:30.677004Z","iopub.execute_input":"2026-01-08T13:00:30.677243Z","iopub.status.idle":"2026-01-08T13:00:31.132686Z","shell.execute_reply.started":"2026-01-08T13:00:30.677228Z","shell.execute_reply":"2026-01-08T13:00:31.132099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd.drop(columns=['No_Finding'], inplace=True)","metadata":{"id":"oFkOA2ome6A0","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.133647Z","iopub.execute_input":"2026-01-08T13:00:31.133970Z","iopub.status.idle":"2026-01-08T13:00:31.159497Z","shell.execute_reply.started":"2026-01-08T13:00:31.133941Z","shell.execute_reply":"2026-01-08T13:00:31.158902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd.columns","metadata":{"id":"POIsAm1Fdt5_","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.160242Z","iopub.execute_input":"2026-01-08T13:00:31.160500Z","iopub.status.idle":"2026-01-08T13:00:31.165461Z","shell.execute_reply.started":"2026-01-08T13:00:31.160482Z","shell.execute_reply":"2026-01-08T13:00:31.164814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd.shape","metadata":{"id":"FdzII4JpfHPB","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.166252Z","iopub.execute_input":"2026-01-08T13:00:31.166541Z","iopub.status.idle":"2026-01-08T13:00:31.177431Z","shell.execute_reply.started":"2026-01-08T13:00:31.166515Z","shell.execute_reply":"2026-01-08T13:00:31.176709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd[\"Unnamed: 11\"]","metadata":{"id":"zSiuVswTf48K","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.178246Z","iopub.execute_input":"2026-01-08T13:00:31.178580Z","iopub.status.idle":"2026-01-08T13:00:31.189117Z","shell.execute_reply.started":"2026-01-08T13:00:31.178559Z","shell.execute_reply":"2026-01-08T13:00:31.188243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd = data_clean_pd.drop(columns=['Unnamed: 11'])\n","metadata":{"id":"jTfVH099gZuD","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.190003Z","iopub.execute_input":"2026-01-08T13:00:31.190250Z","iopub.status.idle":"2026-01-08T13:00:31.208869Z","shell.execute_reply.started":"2026-01-08T13:00:31.190228Z","shell.execute_reply":"2026-01-08T13:00:31.208139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd[\"Image Index\"]","metadata":{"id":"MxncTLyKgbEl","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.209655Z","iopub.execute_input":"2026-01-08T13:00:31.209935Z","iopub.status.idle":"2026-01-08T13:00:31.215469Z","shell.execute_reply.started":"2026-01-08T13:00:31.209918Z","shell.execute_reply":"2026-01-08T13:00:31.214734Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1 row for each photo","metadata":{"id":"UdA0YKEThe_D"}},{"cell_type":"code","source":"data_clean_pd[\"Patient ID\"]","metadata":{"id":"wfhngrEZgjHG","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.216292Z","iopub.execute_input":"2026-01-08T13:00:31.216561Z","iopub.status.idle":"2026-01-08T13:00:31.226451Z","shell.execute_reply.started":"2026-01-08T13:00:31.216542Z","shell.execute_reply":"2026-01-08T13:00:31.225847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd[\"Patient ID\"].value_counts()","metadata":{"id":"UOff_TqWgvhP","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.226989Z","iopub.execute_input":"2026-01-08T13:00:31.227157Z","iopub.status.idle":"2026-01-08T13:00:31.242361Z","shell.execute_reply.started":"2026-01-08T13:00:31.227143Z","shell.execute_reply":"2026-01-08T13:00:31.241628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Total number of patients is {len(data_clean_pd[\"Patient ID\"].value_counts())}')","metadata":{"id":"Wii3JQNyg5xg","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.243165Z","iopub.execute_input":"2026-01-08T13:00:31.243745Z","iopub.status.idle":"2026-01-08T13:00:31.253599Z","shell.execute_reply.started":"2026-01-08T13:00:31.243725Z","shell.execute_reply":"2026-01-08T13:00:31.252786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd.columns","metadata":{"id":"56tW0g1ahkV7","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.254544Z","iopub.execute_input":"2026-01-08T13:00:31.254846Z","iopub.status.idle":"2026-01-08T13:00:31.264988Z","shell.execute_reply.started":"2026-01-08T13:00:31.254827Z","shell.execute_reply":"2026-01-08T13:00:31.264200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"disease_counts = data_clean_pd[diseases].sum().sort_values(ascending=False)\nprint(disease_counts)\n","metadata":{"id":"nI7N21EKrTis","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.265827Z","iopub.execute_input":"2026-01-08T13:00:31.266066Z","iopub.status.idle":"2026-01-08T13:00:31.291769Z","shell.execute_reply.started":"2026-01-08T13:00:31.266043Z","shell.execute_reply":"2026-01-08T13:00:31.291092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(disease_counts/1121.20)","metadata":{"id":"qPWu298U46RU","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.292491Z","iopub.execute_input":"2026-01-08T13:00:31.293229Z","iopub.status.idle":"2026-01-08T13:00:31.297795Z","shell.execute_reply.started":"2026-01-08T13:00:31.293211Z","shell.execute_reply":"2026-01-08T13:00:31.297111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,5))\ndisease_counts.plot(kind='bar')\nplt.title(\"Disease Distribution in NIH Chest X-ray\")\nplt.ylabel(\"Number of Images\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n","metadata":{"id":"cihAVyzkqXlO","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.298547Z","iopub.execute_input":"2026-01-08T13:00:31.298734Z","iopub.status.idle":"2026-01-08T13:00:31.678353Z","shell.execute_reply.started":"2026-01-08T13:00:31.298711Z","shell.execute_reply":"2026-01-08T13:00:31.677695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_clean_pd['num_diseases'] = data_clean_pd[diseases].sum(axis=1)\n\ndata_clean_pd['num_diseases'].value_counts().sort_index()\n","metadata":{"id":"egS6YzOOrbSV","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.679050Z","iopub.execute_input":"2026-01-08T13:00:31.679243Z","iopub.status.idle":"2026-01-08T13:00:31.721369Z","shell.execute_reply.started":"2026-01-08T13:00:31.679228Z","shell.execute_reply":"2026-01-08T13:00:31.720581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport numpy as np\n\nco_matrix = np.dot(\n    data_clean_pd[diseases].T,\n    data_clean_pd[diseases]\n)\n\nco_df = pd.DataFrame(co_matrix, index=diseases, columns=diseases)\n\nplt.figure(figsize=(10,8))\nsns.heatmap(co_df, cmap='Reds')\nplt.title(\"Disease Co-occurrence Matrix\")\nplt.show()\n","metadata":{"id":"iiFF3MU7roer","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:31.722206Z","iopub.execute_input":"2026-01-08T13:00:31.722469Z","iopub.status.idle":"2026-01-08T13:00:32.203921Z","shell.execute_reply.started":"2026-01-08T13:00:31.722451Z","shell.execute_reply":"2026-01-08T13:00:32.203254Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#To overecome class imbalance","metadata":{"id":"CfyHN_R76wg4"}},{"cell_type":"code","source":"import numpy as np\n\npos_counts = disease_counts.values\nneg_counts = len(data_clean_pd) - pos_counts\n\nclass_weights = neg_counts / (pos_counts + 1e-6)\nclass_weights = class_weights / class_weights.mean()  # normalize\n\nclass_weights\n","metadata":{"id":"oXMKrsWt61O5","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.204779Z","iopub.execute_input":"2026-01-08T13:00:32.205538Z","iopub.status.idle":"2026-01-08T13:00:32.211244Z","shell.execute_reply.started":"2026-01-08T13:00:32.205515Z","shell.execute_reply":"2026-01-08T13:00:32.210684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(class_weights))\ncan use the above weight thing in the training","metadata":{"id":"xYctdQpo7MgC"}},{"cell_type":"markdown","source":"# Test Train Validation Dataset Creation","metadata":{"id":"WcLIYXD0NtHm"}},{"cell_type":"code","source":"import numpy as np\n\npatient_ids = data_clean_pd[\"Patient ID\"].unique()\nprint(\"Total patients:\", len(patient_ids))\n","metadata":{"id":"Cl2OT8dMNy5T","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.212041Z","iopub.execute_input":"2026-01-08T13:00:32.212298Z","iopub.status.idle":"2026-01-08T13:00:32.222867Z","shell.execute_reply.started":"2026-01-08T13:00:32.212276Z","shell.execute_reply":"2026-01-08T13:00:32.222198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(42)\nnp.random.shuffle(patient_ids)\n","metadata":{"id":"nvif_-XCTkT_","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.223522Z","iopub.execute_input":"2026-01-08T13:00:32.223764Z","iopub.status.idle":"2026-01-08T13:00:32.232279Z","shell.execute_reply.started":"2026-01-08T13:00:32.223747Z","shell.execute_reply":"2026-01-08T13:00:32.231555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_patients = len(patient_ids)\n\ntrain_end = int(0.70 * n_patients)\nval_end   = int(0.85 * n_patients)\n\ntrain_patients = patient_ids[:train_end]\nval_patients   = patient_ids[train_end:val_end]\ntest_patients  = patient_ids[val_end:]\n","metadata":{"id":"l_FAV5rUTn9p","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.233056Z","iopub.execute_input":"2026-01-08T13:00:32.233673Z","iopub.status.idle":"2026-01-08T13:00:32.243047Z","shell.execute_reply.started":"2026-01-08T13:00:32.233655Z","shell.execute_reply":"2026-01-08T13:00:32.242281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = data_clean_pd[data_clean_pd[\"Patient ID\"].isin(train_patients)].reset_index(drop=True)\nval_df   = data_clean_pd[data_clean_pd[\"Patient ID\"].isin(val_patients)].reset_index(drop=True)\ntest_df  = data_clean_pd[data_clean_pd[\"Patient ID\"].isin(test_patients)].reset_index(drop=True)\n\nprint(\"Train images:\", len(train_df))\nprint(\"Val images:\", len(val_df))\nprint(\"Test images:\", len(test_df))\n","metadata":{"id":"IxdFTgMtTsYu","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.243839Z","iopub.execute_input":"2026-01-08T13:00:32.244109Z","iopub.status.idle":"2026-01-08T13:00:32.310350Z","shell.execute_reply.started":"2026-01-08T13:00:32.244083Z","shell.execute_reply":"2026-01-08T13:00:32.309682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"assert set(train_df[\"Patient ID\"]).isdisjoint(val_df[\"Patient ID\"])\nassert set(train_df[\"Patient ID\"]).isdisjoint(test_df[\"Patient ID\"])\nassert set(val_df[\"Patient ID\"]).isdisjoint(test_df[\"Patient ID\"])\n\nprint(\"✅ No patient leakage between splits\")\n","metadata":{"id":"oWOD8f7cT6Mt","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.311064Z","iopub.execute_input":"2026-01-08T13:00:32.311344Z","iopub.status.idle":"2026-01-08T13:00:32.337339Z","shell.execute_reply.started":"2026-01-08T13:00:32.311304Z","shell.execute_reply":"2026-01-08T13:00:32.336635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = [\n    'Atelectasis','Cardiomegaly','Effusion','Infiltration',\n    'Mass','Nodule','Pneumonia','Pneumothorax',\n    'Consolidation','Edema','Emphysema','Fibrosis',\n    'Pleural_Thickening','Hernia'\n]\n\ndef label_stats(df, name):\n    print(f\"\\n{name} label counts:\")\n    print(df[labels].sum())\n\nlabel_stats(train_df, \"Train\")\nlabel_stats(val_df, \"Validation\")\nlabel_stats(test_df, \"Test\")\n","metadata":{"id":"R-I8N65cT-Fe","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.338084Z","iopub.execute_input":"2026-01-08T13:00:32.338344Z","iopub.status.idle":"2026-01-08T13:00:32.356387Z","shell.execute_reply.started":"2026-01-08T13:00:32.338306Z","shell.execute_reply":"2026-01-08T13:00:32.355748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.to_csv(\"train_patient_split.csv\", index=False)\nval_df.to_csv(\"val_patient_split.csv\", index=False)\ntest_df.to_csv(\"test_patient_split.csv\", index=False)\n","metadata":{"id":"NFU-vHsRUDsz","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:32.357857Z","iopub.execute_input":"2026-01-08T13:00:32.358071Z","iopub.status.idle":"2026-01-08T13:00:33.173173Z","shell.execute_reply.started":"2026-01-08T13:00:32.358038Z","shell.execute_reply":"2026-01-08T13:00:33.172247Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now Time for training","metadata":{"id":"RK_OD6a_VRU6"}},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:33.174033Z","iopub.execute_input":"2026-01-08T13:00:33.174240Z","iopub.status.idle":"2026-01-08T13:00:33.178083Z","shell.execute_reply.started":"2026-01-08T13:00:33.174223Z","shell.execute_reply":"2026-01-08T13:00:33.177500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:33.178852Z","iopub.execute_input":"2026-01-08T13:00:33.179021Z","iopub.status.idle":"2026-01-08T13:00:33.258798Z","shell.execute_reply.started":"2026-01-08T13:00:33.179007Z","shell.execute_reply":"2026-01-08T13:00:33.258141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef build_image_index(image_root):\n    image_index = {}\n    for root, _, files in os.walk(image_root):\n        for f in files:\n            if f.endswith(\".png\") or f.endswith(\".jpg\"):\n                image_index[f] = os.path.join(root, f)\n    return image_index\n","metadata":{"id":"9G7JkQVsVTjk","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:33.259564Z","iopub.execute_input":"2026-01-08T13:00:33.259832Z","iopub.status.idle":"2026-01-08T13:00:33.270142Z","shell.execute_reply.started":"2026-01-08T13:00:33.259807Z","shell.execute_reply":"2026-01-08T13:00:33.269501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_ROOT = path  # dataset root from kagglehub\nimage_index = build_image_index(IMAGE_ROOT)\n\nprint(\"Total images indexed:\", len(image_index))\n","metadata":{"id":"Oh8yIbWRVggj","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:00:33.271021Z","iopub.execute_input":"2026-01-08T13:00:33.271337Z","iopub.status.idle":"2026-01-08T13:02:24.956659Z","shell.execute_reply.started":"2026-01-08T13:00:33.271296Z","shell.execute_reply":"2026-01-08T13:02:24.955887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\nval_test_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"id":"2y9PmICnVqVH","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:24.957377Z","iopub.execute_input":"2026-01-08T13:02:24.957599Z","iopub.status.idle":"2026-01-08T13:02:28.197966Z","shell.execute_reply.started":"2026-01-08T13:02:24.957573Z","shell.execute_reply":"2026-01-08T13:02:28.197365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\n\nclass ChestXrayDataset(Dataset):\n    def __init__(self, df, image_index, transform=None, label_cols=None):\n        self.df = df.reset_index(drop=True)\n        self.image_index = image_index\n        self.transform = transform\n        self.label_cols = label_cols\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n\n        # --- Load image ---\n        image_name = row[\"Image Index\"]\n        image_path = self.image_index[image_name]\n        image = Image.open(image_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        # --- Load labels ---\n        labels = row[self.label_cols].values.astype(\"float32\")\n        labels = torch.tensor(labels)\n\n        return image, labels\n","metadata":{"id":"UGDGkMPOVzVm","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:28.198611Z","iopub.execute_input":"2026-01-08T13:02:28.198955Z","iopub.status.idle":"2026-01-08T13:02:28.204927Z","shell.execute_reply.started":"2026-01-08T13:02:28.198938Z","shell.execute_reply":"2026-01-08T13:02:28.204028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# label_cols = [\n#     'Atelectasis','Cardiomegaly','Effusion','Infiltration',\n#     'Mass','Nodule','Pneumonia','Pneumothorax',\n#     'Consolidation','Edema','Emphysema','Fibrosis',\n#     'Pleural_Thickening','Hernia'\n# ]\n\ntrain_dataset = ChestXrayDataset(\n    train_df, image_index,\n    transform=train_transform,\n    label_cols=diseases\n)\n\nval_dataset = ChestXrayDataset(\n    val_df, image_index,\n    transform=val_test_transform,\n    label_cols=diseases\n)\n\ntest_dataset = ChestXrayDataset(\n    test_df, image_index,\n    transform=val_test_transform,\n    label_cols=diseases\n)\n","metadata":{"id":"XWigU2Q6WDFB","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:28.206222Z","iopub.execute_input":"2026-01-08T13:02:28.206585Z","iopub.status.idle":"2026-01-08T13:02:28.237905Z","shell.execute_reply.started":"2026-01-08T13:02:28.206556Z","shell.execute_reply":"2026-01-08T13:02:28.237357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nBATCH_SIZE = 16\nNUM_WORKERS = 2 # Colab-safe\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n","metadata":{"id":"Lek-b5C6WXOi","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:28.238610Z","iopub.execute_input":"2026-01-08T13:02:28.238817Z","iopub.status.idle":"2026-01-08T13:02:28.243460Z","shell.execute_reply.started":"2026-01-08T13:02:28.238800Z","shell.execute_reply":"2026-01-08T13:02:28.242746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:28.244190Z","iopub.execute_input":"2026-01-08T13:02:28.244461Z","iopub.status.idle":"2026-01-08T13:02:28.256229Z","shell.execute_reply.started":"2026-01-08T13:02:28.244442Z","shell.execute_reply":"2026-01-08T13:02:28.255360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:28.256958Z","iopub.execute_input":"2026-01-08T13:02:28.257576Z","iopub.status.idle":"2026-01-08T13:02:28.268761Z","shell.execute_reply.started":"2026-01-08T13:02:28.257558Z","shell.execute_reply":"2026-01-08T13:02:28.268212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, labels = next(iter(train_loader))\nprint(\"Image batch shape:\", images.shape)   # [B, 3, 224, 224]\nprint(\"Label batch shape:\", labels.shape)   # [B, 14]\n","metadata":{"id":"Tg04Il71WkXj","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:28.269472Z","iopub.execute_input":"2026-01-08T13:02:28.269704Z","iopub.status.idle":"2026-01-08T13:02:29.619482Z","shell.execute_reply.started":"2026-01-08T13:02:28.269683Z","shell.execute_reply":"2026-01-08T13:02:29.618695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n","metadata":{"id":"nuc1P89TXDLE","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:29.620434Z","iopub.execute_input":"2026-01-08T13:02:29.620708Z","iopub.status.idle":"2026-01-08T13:02:29.624953Z","shell.execute_reply.started":"2026-01-08T13:02:29.620676Z","shell.execute_reply":"2026-01-08T13:02:29.624201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class DenseNet121(nn.Module):\n#     def __init__(self, num_classes=14):\n#         super(DenseNet121, self).__init__()\n\n#         # Load pretrained DenseNet-121\n#         self.backbone = models.densenet121(weights=\"IMAGENET1K_V1\")\n\n#         # Number of features before classifier\n#         num_features = self.backbone.classifier.in_features\n\n#         # Replace classifier\n#         self.backbone.classifier = nn.Linear(num_features, num_classes)\n\n#     def forward(self, x):\n#         return self.backbone(x)\n","metadata":{"id":"u8WLOenEXHcH","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:29.625813Z","iopub.execute_input":"2026-01-08T13:02:29.626514Z","iopub.status.idle":"2026-01-08T13:02:29.636663Z","shell.execute_reply.started":"2026-01-08T13:02:29.626493Z","shell.execute_reply":"2026-01-08T13:02:29.635893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass DenseNet121_new(nn.Module):\n    def __init__(self, num_classes=14):\n        super(DenseNet121_new, self).__init__()\n\n        self.backbone = models.densenet121(weights=\"IMAGENET1K_V1\")\n        num_features = self.backbone.classifier.in_features\n\n        # Remove classifier from backbone\n        self.backbone.classifier = nn.Identity()\n\n        # Our classifier head\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def get_embedding(self, x):\n        features = self.backbone(x)  # (B, 1024)\n        return features\n\n    def forward(self, x):\n        features = self.get_embedding(x)\n        logits = self.classifier(features)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:29.637488Z","iopub.execute_input":"2026-01-08T13:02:29.637699Z","iopub.status.idle":"2026-01-08T13:02:29.649151Z","shell.execute_reply.started":"2026-01-08T13:02:29.637675Z","shell.execute_reply":"2026-01-08T13:02:29.648369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data = train_dataset[0][0].to(device=\"cuda\", dtype=torch.float32)\n# b = torch.unsqueeze(data, dim=0)\n# c=model.get_embedding(b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:29.649934Z","iopub.execute_input":"2026-01-08T13:02:29.650219Z","iopub.status.idle":"2026-01-08T13:02:29.660150Z","shell.execute_reply.started":"2026-01-08T13:02:29.650193Z","shell.execute_reply":"2026-01-08T13:02:29.659547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model is currently set to basic imagenet class which results both logits and embeddings","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = DenseNet121_new(num_classes=14)\n\n\n\nmodel_bce = model.to(device)\nmodel_supcon = model.to(device)\nmodel_graph = model.to(device)\n\nprint(\"Model loaded on:\", device)\n","metadata":{"id":"ENmZjp4LXP_C","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:29.660918Z","iopub.execute_input":"2026-01-08T13:02:29.661156Z","iopub.status.idle":"2026-01-08T13:02:30.569267Z","shell.execute_reply.started":"2026-01-08T13:02:29.661131Z","shell.execute_reply":"2026-01-08T13:02:30.568640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_weights.dtype","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.570192Z","iopub.execute_input":"2026-01-08T13:02:30.570855Z","iopub.status.idle":"2026-01-08T13:02:30.575798Z","shell.execute_reply.started":"2026-01-08T13:02:30.570828Z","shell.execute_reply":"2026-01-08T13:02:30.574974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# numpy_array = class_weights.numpy()\ntorch_tensor = torch.from_numpy(class_weights)\nclass_weights = torch_tensor.to(torch.float32) \nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.576760Z","iopub.execute_input":"2026-01-08T13:02:30.577026Z","iopub.status.idle":"2026-01-08T13:02:30.587123Z","shell.execute_reply.started":"2026-01-08T13:02:30.577003Z","shell.execute_reply":"2026-01-08T13:02:30.586441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass AsymmetricLoss(nn.Module):\n    def __init__(\n        self,\n        gamma_pos=0,\n        gamma_neg=4,\n        clip=0.05,\n        eps=1e-8\n    ):\n        super().__init__()\n        self.gamma_pos = gamma_pos\n        self.gamma_neg = gamma_neg\n        self.clip = clip\n        self.eps = eps\n\n    def forward(self, logits, targets):\n        \"\"\"\n        logits: (batch_size, num_classes)\n        targets: (batch_size, num_classes) with {0,1}\n        \"\"\"\n\n        probs = torch.sigmoid(logits)\n\n        # Optional probability clipping\n        if self.clip is not None and self.clip > 0:\n            probs = torch.clamp(probs, min=self.clip, max=1 - self.clip)\n\n        pos_loss = targets * torch.log(probs + self.eps)\n        neg_loss = (1 - targets) * torch.log(1 - probs + self.eps)\n\n        # Asymmetric focusing\n        pos_weight = torch.pow(1 - probs, self.gamma_pos)\n        neg_weight = torch.pow(probs, self.gamma_neg)\n\n        loss = - (pos_weight * pos_loss + neg_weight * neg_loss)\n\n        return loss.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.587905Z","iopub.execute_input":"2026-01-08T13:02:30.588124Z","iopub.status.idle":"2026-01-08T13:02:30.598018Z","shell.execute_reply.started":"2026-01-08T13:02:30.588101Z","shell.execute_reply":"2026-01-08T13:02:30.597341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        self.bce = nn.BCEWithLogitsLoss(reduction=\"none\")\n\n    def forward(self, logits, targets):\n        bce = self.bce(logits, targets)\n        probs = torch.sigmoid(logits)\n        focal = (1 - probs) ** self.gamma\n        return (focal * bce).mean()\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.598752Z","iopub.execute_input":"2026-01-08T13:02:30.598994Z","iopub.status.idle":"2026-01-08T13:02:30.610973Z","shell.execute_reply.started":"2026-01-08T13:02:30.598977Z","shell.execute_reply":"2026-01-08T13:02:30.610286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SupConLossMultiLabel(nn.Module):\n    def __init__(self, temperature=0.07):\n        super().__init__()\n        self.temperature = temperature\n\n    def forward(self, embeddings, labels):\n        device = embeddings.device\n        B = embeddings.size(0)\n\n        embeddings = F.normalize(embeddings, dim=1)\n\n        # Cosine similarity\n        sim = torch.matmul(embeddings, embeddings.T) / self.temperature\n        sim = sim - torch.max(sim, dim=1, keepdim=True)[0]\n\n        # Positive mask: share at least one label\n        label_sim = (labels @ labels.T) > 0\n        label_sim = label_sim.float().to(device)\n\n        # Remove self-contrast\n        mask = torch.eye(B, device=device)\n        label_sim = label_sim * (1 - mask)\n\n        # 🚨 CRITICAL FIX: no positive pairs\n        if label_sim.sum().item() == 0:\n            return torch.zeros(1, device=device, requires_grad=True).squeeze()\n\n        exp_sim = torch.exp(sim) * (1 - mask)\n        log_prob = sim - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-8)\n\n        mean_log_prob_pos = (\n            (label_sim * log_prob).sum(dim=1) /\n            (label_sim.sum(dim=1) + 1e-8)\n        )\n\n        loss = -mean_log_prob_pos.mean()\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.625052Z","iopub.execute_input":"2026-01-08T13:02:30.625250Z","iopub.status.idle":"2026-01-08T13:02:30.631873Z","shell.execute_reply.started":"2026-01-08T13:02:30.625235Z","shell.execute_reply":"2026-01-08T13:02:30.631385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n\ny_train = torch.tensor(\n    train_df[diseases].values,\n    dtype=torch.float32\n).to(device)\n\n\n\npos_counts = y_train.sum(dim=0)              # positives per disease\nneg_counts = y_train.shape[0] - pos_counts   # negatives\n\npos_weight = neg_counts / (pos_counts + 1e-6)\npos_weight = pos_weight.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.632552Z","iopub.execute_input":"2026-01-08T13:02:30.632760Z","iopub.status.idle":"2026-01-08T13:02:30.701515Z","shell.execute_reply.started":"2026-01-08T13:02:30.632738Z","shell.execute_reply":"2026-01-08T13:02:30.700718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion_asl = AsymmetricLoss(gamma_pos=0,gamma_neg=4,clip=0.05)\nloss_asl=criterion_asl\n\ncriterion_focal = FocalLoss(gamma=2)\nloss_focal=criterion_focal\n\ncriterion_wbce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\nloss_wbce=criterion_wbce\n\ncriterion_bce = nn.BCEWithLogitsLoss()\nloss_bce=criterion_bce\n\ncriterion_supcon=SupConLossMultiLabel(temperature=0.07)\nsupcon_loss=criterion_supcon","metadata":{"id":"Hel17NKvXYr3","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.702284Z","iopub.execute_input":"2026-01-08T13:02:30.702556Z","iopub.status.idle":"2026-01-08T13:02:30.707223Z","shell.execute_reply.started":"2026-01-08T13:02:30.702531Z","shell.execute_reply":"2026-01-08T13:02:30.706546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# criterion_supcon\n# criterion_asl\n# criterion_bce\n# criterion_wbce\n# criterion_focal","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.707831Z","iopub.execute_input":"2026-01-08T13:02:30.707998Z","iopub.status.idle":"2026-01-08T13:02:30.719169Z","shell.execute_reply.started":"2026-01-08T13:02:30.707986Z","shell.execute_reply":"2026-01-08T13:02:30.718624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimizer and scheduler default , all the lr weight decay and scheduler params are here","metadata":{}},{"cell_type":"code","source":"def build_optimizer(model,\n                    lr_backbone=1e-5,\n                    lr_head=9e-3,\n                    weight_decay=2e-5):\n    \"\"\"\n    Builds AdamW optimizer with discriminative learning rates.\n    Freezing/unfreezing is handled via requires_grad.\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        [\n            {\n                \"params\": model.backbone.features.parameters(),\n                \"lr\": lr_backbone,\n            },\n            {\n                \"params\": model.backbone.classifier.parameters(),\n                \"lr\": lr_head,\n            },\n        ],\n        weight_decay=weight_decay,\n    )\n    return optimizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.719821Z","iopub.execute_input":"2026-01-08T13:02:30.720051Z","iopub.status.idle":"2026-01-08T13:02:30.732493Z","shell.execute_reply.started":"2026-01-08T13:02:30.720036Z","shell.execute_reply":"2026-01-08T13:02:30.731823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# optimizer = torch.optim.AdamW(\n#     model.parameters(),\n#     lr=1e-4,\n#     weight_decay=1e-4\n# )\nfrom transformers import get_cosine_schedule_with_warmup\noptimizer_core = torch.optim.AdamW([\n    {'params': model.backbone.features.parameters(), 'lr': 1e-5},\n    {'params': model.backbone.classifier.parameters(), 'lr': 9e-3},\n], weight_decay=2e-5)\n\ntotal_steps = len(train_loader) * 10\n\n\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer_core,\n    num_warmup_steps=int(0.1 * total_steps),\n    num_training_steps=total_steps\n)\n","metadata":{"id":"Er8Oc9vfXeNa","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:30.733070Z","iopub.execute_input":"2026-01-08T13:02:30.733305Z","iopub.status.idle":"2026-01-08T13:02:32.483209Z","shell.execute_reply.started":"2026-01-08T13:02:30.733285Z","shell.execute_reply":"2026-01-08T13:02:32.482588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Basic untrained Imagenet","metadata":{}},{"cell_type":"code","source":"model.train()\nimages, labels = next(iter(train_loader))\n\nimages = images.to(device)\nlabels = labels.to(device)\n\noutputs = model(images)\n\nprint(\"Output shape:\", outputs.shape)   # [B, 14]\nprint(\"Label shape:\", labels.shape)     # [B, 14]\n\nloss_asl = criterion_asl(outputs, labels)\nloss_supcon = criterion_supcon(outputs, labels)\nloss_bce = criterion_bce(outputs, labels)\nloss_wbce = criterion_wbce(outputs, labels)\nloss_focal = criterion_focal(outputs, labels)\n\nprint(\"Initial loss:\", loss_asl.item())\nprint(\"Initial loss:\", loss_focal.item())\nprint(\"Initial loss:\", loss_bce.item())\nprint(\"Initial loss:\", loss_wbce.item())\nprint(\"Initial loss:\", loss_supcon.item())","metadata":{"id":"8Jeex2sCXkCU","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:32.484022Z","iopub.execute_input":"2026-01-08T13:02:32.484410Z","iopub.status.idle":"2026-01-08T13:02:34.747967Z","shell.execute_reply.started":"2026-01-08T13:02:32.484389Z","shell.execute_reply":"2026-01-08T13:02:34.747192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n","metadata":{"id":"NR9vIoPGX3wE","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:34.749055Z","iopub.execute_input":"2026-01-08T13:02:34.749701Z","iopub.status.idle":"2026-01-08T13:02:34.872668Z","shell.execute_reply.started":"2026-01-08T13:02:34.749673Z","shell.execute_reply":"2026-01-08T13:02:34.872054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate_auroc(model, dataloader, device):\n    model.eval()\n\n    all_labels = []\n    all_outputs = []\n\n    for images, labels in dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        logits = model(images)\n        probs = torch.sigmoid(logits)\n\n        all_outputs.append(probs.cpu().numpy())\n        all_labels.append(labels.cpu().numpy())\n\n    all_outputs = np.concatenate(all_outputs, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n\n    aucs = []\n    for i in range(all_labels.shape[1]):\n        try:\n            auc = roc_auc_score(all_labels[:, i], all_outputs[:, i])\n        except ValueError:\n            auc = np.nan  # happens if only one class present\n        aucs.append(auc)\n\n    mean_auc = np.nanmean(aucs)\n    return mean_auc, aucs\n","metadata":{"id":"a8ZnqRYJX8uk","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:34.873458Z","iopub.execute_input":"2026-01-08T13:02:34.873649Z","iopub.status.idle":"2026-01-08T13:02:34.879540Z","shell.execute_reply.started":"2026-01-08T13:02:34.873634Z","shell.execute_reply":"2026-01-08T13:02:34.878807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EPOCHS = 5\n# best_val_auc = 0.0\n\n\n# # optimizer = torch.optim.AdamW([\n# #     {'params': model_bce.backbone.features.parameters(), 'lr': 1e-5},\n# #     {'params': model_bce.backbone.classifier.parameters(), 'lr': 9e-3},\n# # ], weight_decay=2e-5)\n\n# optimizer=build_optimizer(model_bce, lr_backbone=1e-5,lr_head=9e-3,weight_decay=2e-5)\n\n# model_bce.train()\n\n# for p in model_bce.backbone.features.parameters():\n#     p.requires_grad = False\n\n# try:\n#     for epoch in range(EPOCHS):\n#         model_bce.train()\n#         running_loss = 0.0\n\n#         loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{EPOCHS}]\")\n\n#         if epoch==UNFREEZE_EPOCH:\n#             for p in model_bce.backbone.features.parameters():\n#                 p.requires_grad = False\n\n        \n#         for images, labels in loop:\n#             images = images.to(device)\n#             labels = labels.to(device).float()   # ✅ IMPORTANT\n\n#             optimizer.zero_grad()\n\n#             logits = model_bce(images)\n#             loss = criterion_bce(logits, labels)\n\n#             loss.backward()\n\n#             # ✅ Clip gradients BEFORE optimizer step\n#             torch.nn.utils.clip_grad_norm_(model_bce.parameters(), 1.0)\n\n#             optimizer.step()\n#             scheduler.step()\n\n#             running_loss += loss.item()\n#             loop.set_postfix(loss=loss.item())\n\n#         avg_train_loss = running_loss / len(train_loader)\n\n#         # --------------------\n#         # Validation\n#         # --------------------\n#         val_mean_auc, val_aucs = evaluate_auroc(model_bce, val_loader, device)\n\n#         print(f\"\\nEpoch {epoch+1}\")\n#         print(f\"Train Loss: {avg_train_loss:.4f}\")\n#         print(f\"Val Mean AUROC: {val_mean_auc:.4f}\")\n\n#         # --------------------\n#         # Save best model\n#         # --------------------\n#         if val_mean_auc > best_val_auc:\n#             best_val_auc = val_mean_auc\n#             torch.save(model_bce.state_dict(), \"best_densenet121.pth\")\n#             print(\"✅ Best model saved\")\n\n# except:\n \n#     print(\"⛔ Training interrupted — saving last model...\")\n#     torch.save(model_bce.state_dict(), \"interrupt_last.pth\")\n\nEPOCHS = 5\nUNFREEZE_EPOCH = 2\nbest_val_auc = 0.0\n\noptimizer = build_optimizer(\n    model_bce,\n    lr_backbone=1e-5,\n    lr_head=9e-3,\n    weight_decay=2e-5\n)\n\n# scheduler = build_scheduler(\n#     optimizer,\n#     num_training_steps=len(train_loader) * EPOCHS,\n#     num_warmup_steps=0.1\n# )\n\n# 🔒 Freeze backbone initially\nfor p in model_bce.backbone.features.parameters():\n    p.requires_grad = False\n\ntry:\n    for epoch in range(EPOCHS):\n        model_bce.train()\n        running_loss = 0.0\n\n        # 🔓 Unfreeze backbone\n        if epoch == UNFREEZE_EPOCH:\n            print(\"🔓 Unfreezing backbone\")\n            for p in model_bce.backbone.features.parameters():\n                p.requires_grad = True\n\n        loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{EPOCHS}]\")\n\n        for images, labels in loop:\n            images = images.to(device)\n            labels = labels.to(device).float()\n\n            optimizer.zero_grad()\n\n            logits = model_bce(images)\n            loss = criterion_bce(logits, labels)\n\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model_bce.parameters(), 1.0)\n\n            optimizer.step()\n            scheduler.step()\n\n            running_loss += loss.item()\n            loop.set_postfix(loss=loss.item())\n\n        avg_train_loss = running_loss / len(train_loader)\n\n        # Validation\n        val_mean_auc, _ = evaluate_auroc(model_bce, val_loader, device)\n\n        print(f\"\\nEpoch {epoch+1}\")\n        print(f\"Train Loss: {avg_train_loss:.4f}\")\n        print(f\"Val Mean AUROC: {val_mean_auc:.4f}\")\n\n        if val_mean_auc > best_val_auc:\n            best_val_auc = val_mean_auc\n            torch.save(model_bce.state_dict(), \"best_densenet121_bce.pth\")\n            print(\"✅ Best model saved\")\n\nexcept KeyboardInterrupt:\n    print(\"⛔ Training interrupted — saving last model...\")\n    torch.save(model_bce.state_dict(), \"interrupt_last_bce.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:02:34.880461Z","iopub.execute_input":"2026-01-08T13:02:34.880666Z","iopub.status.idle":"2026-01-08T13:03:42.381828Z","shell.execute_reply.started":"2026-01-08T13:02:34.880651Z","shell.execute_reply":"2026-01-08T13:03:42.380954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n# Full path is recommended to ensure it's in the working directory\ntorch.save(model_bce.state_dict(), '/kaggle/working/best_densenet121_asl_supcon.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:42.382847Z","iopub.execute_input":"2026-01-08T13:03:42.383105Z","iopub.status.idle":"2026-01-08T13:03:42.471558Z","shell.execute_reply.started":"2026-01-08T13:03:42.383080Z","shell.execute_reply":"2026-01-08T13:03:42.470806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n# Note: Do NOT include \"/kaggle/working/\" in the path string\nFileLink(r'best_densenet121_asl_supcon.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:42.472424Z","iopub.execute_input":"2026-01-08T13:03:42.472694Z","iopub.status.idle":"2026-01-08T13:03:42.478237Z","shell.execute_reply.started":"2026-01-08T13:03:42.472668Z","shell.execute_reply":"2026-01-08T13:03:42.477591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 10\nUNFREEZE_EPOCH = 2\nbest_val_auc = 0.0\nlambda_supcon = 0.1\n\noptimizer = build_optimizer(\n    model_supcon,\n    lr_backbone=1e-5,\n    lr_head=9e-3,\n    weight_decay=2e-5\n)\n\n# 🔒 Freeze backbone initially\nfor p in model_supcon.backbone.features.parameters():\n    p.requires_grad = False\n\nglobal_step = 0\n\ntry:\n    for epoch in range(EPOCHS):\n        model_supcon.train()\n        running_loss = 0.0\n\n        # 🔓 Unfreeze backbone\n        if epoch == UNFREEZE_EPOCH:\n            print(\"🔓 Unfreezing backbone\")\n            for p in model_supcon.backbone.features.parameters():\n                p.requires_grad = True\n\n        loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{EPOCHS}]\")\n\n        for images, labels in loop:\n            images = images.to(device)\n            labels = labels.to(device).float()\n\n            optimizer.zero_grad(set_to_none=True)\n\n            logits = model_supcon(images)\n            loss_cls = criterion_asl(logits, labels)\n\n            # 🔁 SupCon every 2 steps\n            if global_step % 2 == 0:\n                embeddings = model_supcon.get_embedding(images)\n                loss_supcon = criterion_supcon(embeddings, labels)\n                loss = loss_cls + lambda_supcon * loss_supcon\n            else:\n                loss = loss_cls\n\n            # 🚨 Guard against NaN / Inf\n            if not torch.isfinite(loss):\n                optimizer.zero_grad(set_to_none=True)\n                continue\n\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model_supcon.parameters(), 1.0)\n            optimizer.step()\n\n            running_loss += loss.item()\n            loop.set_postfix(loss=loss.item())\n\n            global_step += 1\n\n        avg_train_loss = running_loss / len(train_loader)\n\n        # --------------------\n        # Validation\n        # --------------------\n        val_mean_auc, _ = evaluate_auroc(\n            model_supcon, val_loader, device\n        )\n\n        print(f\"\\nEpoch {epoch+1}\")\n        print(f\"Train Loss: {avg_train_loss:.4f}\")\n        print(f\"Val Mean AUROC: {val_mean_auc:.4f}\")\n\n        if val_mean_auc > best_val_auc:\n            best_val_auc = val_mean_auc\n            torch.save(\n                model_supcon.state_dict(),\n                \"best_densenet121_asl_supcon.pth\"\n            )\n            print(\"✅ Best model saved\")\n\nexcept KeyboardInterrupt:\n    print(\"⛔ Training interrupted — saving last model...\")\n    torch.save(\n        model_supcon.state_dict(),\n        \"interrupt_last_asl_supcon.pth\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:42.479047Z","iopub.execute_input":"2026-01-08T13:03:42.479393Z","iopub.status.idle":"2026-01-08T13:03:56.100311Z","shell.execute_reply.started":"2026-01-08T13:03:42.479371Z","shell.execute_reply":"2026-01-08T13:03:56.099580Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# This is baseline performance","metadata":{}},{"cell_type":"code","source":"# device=torch.device('cpu')\ndevice=torch.device('cuda')\nmodel.load_state_dict(torch.load(\"/kaggle/input/chestx-ray-baseline-and-trained/pytorch/default/1/model_bce_weights (1).pth\",map_location=torch.device('cpu')))\nfinal_val_auc, per_class_auc = evaluate_auroc(model, val_loader, device)\n\nprint(\"Final Validation AUROC:\", final_val_auc)\n\nfor label, auc in zip(diseases, per_class_auc):\n    print(f\"{label}: {auc:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:04:45.983636Z","iopub.execute_input":"2026-01-08T13:04:45.984554Z","iopub.status.idle":"2026-01-08T13:09:39.575616Z","shell.execute_reply.started":"2026-01-08T13:04:45.984517Z","shell.execute_reply":"2026-01-08T13:09:39.574636Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# This is for ASL","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/chestx-ray-baseline-and-trained/pytorch/default/1/best_densenet121_asl_supcon (1).pth\"))\nfinal_val_auc, per_class_auc = evaluate_auroc(model, val_loader, device)\n\nprint(\"Final Validation AUROC:\", final_val_auc)\n\nfor label, auc in zip(diseases, per_class_auc):\n    print(f\"{label}: {auc:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:09:46.580634Z","iopub.execute_input":"2026-01-08T13:09:46.581472Z","iopub.status.idle":"2026-01-08T13:12:58.166045Z","shell.execute_reply.started":"2026-01-08T13:09:46.581430Z","shell.execute_reply":"2026-01-08T13:12:58.165209Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This below is the old one trined result same model but trained , the above one has just added a function to get embeddings else all same but is not trained so we will see what are the differences in that case","metadata":{}},{"cell_type":"markdown","source":"#Taking the embeddings of the images via a trained model in form of 1024 d vector for further use","metadata":{"id":"BRVBw6uTd8Rn"}},{"cell_type":"markdown","source":" It makes the model spatially invariant. It doesn't matter where a pneumonia sign is in the X-ray; the pooling layer captures the global presence of that feature across the whole image.\n","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\n\nclass DenseNet121_Embed(nn.Module):\n    def __init__(self, trained_model):\n        super().__init__()\n        self.features = trained_model.backbone.features\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = trained_model.backbone.classifier\n\n    def forward(self, x):\n        x = self.features(x)\n        x = nn.functional.relu(x, inplace=True)\n        x = self.pool(x)\n        embedding = torch.flatten(x, 1)  # [B, 1024]\n        logits = self.classifier(embedding)\n        return embedding, logits\n","metadata":{"id":"Pl-oA_-Yd7TD","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:19:23.719736Z","iopub.execute_input":"2026-01-08T13:19:23.720092Z","iopub.status.idle":"2026-01-08T13:19:23.726221Z","shell.execute_reply.started":"2026-01-08T13:19:23.720060Z","shell.execute_reply":"2026-01-08T13:19:23.725450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.load_state_dict(torch.load(\"/kaggle/input/best-pth/best_densenet121.pth\"))\n# model.eval()\n\nembed_model = DenseNet121_Embed(model).to(device)\nembed_model.eval()\n","metadata":{"id":"8X217X4XeEl5","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:19:25.740300Z","iopub.execute_input":"2026-01-08T13:19:25.741224Z","iopub.status.idle":"2026-01-08T13:19:25.757596Z","shell.execute_reply.started":"2026-01-08T13:19:25.741194Z","shell.execute_reply":"2026-01-08T13:19:25.756999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.438573Z","iopub.status.idle":"2026-01-08T13:03:58.438882Z","shell.execute_reply.started":"2026-01-08T13:03:58.438725Z","shell.execute_reply":"2026-01-08T13:03:58.438740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = YourModelClass(...) # Replace with your model initialization\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:19:34.143807Z","iopub.execute_input":"2026-01-08T13:19:34.144139Z","iopub.status.idle":"2026-01-08T13:19:34.152694Z","shell.execute_reply.started":"2026-01-08T13:19:34.144117Z","shell.execute_reply":"2026-01-08T13:19:34.152059Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"function to take the embeddings","metadata":{"id":"awlB2enPeUWg"}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.441893Z","iopub.status.idle":"2026-01-08T13:03:58.442258Z","shell.execute_reply.started":"2026-01-08T13:03:58.442069Z","shell.execute_reply":"2026-01-08T13:03:58.442086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\n\n@torch.no_grad()\ndef extract_embeddings(model, dataloader, df, device):\n    model.eval()\n\n    all_embeddings = []\n    all_labels = []\n    all_image_ids = []\n\n    idx = 0\n    for images, labels in tqdm(dataloader):\n        images = images.to(device)\n\n        embeddings, _ = model(images)\n        embeddings = embeddings.cpu().numpy()\n\n        batch_size = images.size(0)\n        image_ids = df.iloc[idx:idx+batch_size][\"Image Index\"].values\n\n        all_embeddings.append(embeddings)\n        all_labels.append(labels.numpy())\n        all_image_ids.extend(image_ids)\n\n        idx += batch_size\n\n    return (\n        np.vstack(all_embeddings),\n        np.vstack(all_labels),\n        np.array(all_image_ids)\n    )\n","metadata":{"id":"OVjrrCXCeN_H","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:19:38.026924Z","iopub.execute_input":"2026-01-08T13:19:38.027519Z","iopub.status.idle":"2026-01-08T13:19:38.033842Z","shell.execute_reply.started":"2026-01-08T13:19:38.027489Z","shell.execute_reply":"2026-01-08T13:19:38.033072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb, train_labels, train_ids = extract_embeddings(\n    embed_model, train_loader, train_df, device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.446104Z","iopub.status.idle":"2026-01-08T13:03:58.446550Z","shell.execute_reply.started":"2026-01-08T13:03:58.446421Z","shell.execute_reply":"2026-01-08T13:03:58.446439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.447573Z","iopub.status.idle":"2026-01-08T13:03:58.447813Z","shell.execute_reply.started":"2026-01-08T13:03:58.447699Z","shell.execute_reply":"2026-01-08T13:03:58.447712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_emb, val_labels, val_ids = extract_embeddings(\n    embed_model, val_loader, val_df, device\n)\n","metadata":{"id":"kSTUOBDWeZVL","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.448996Z","iopub.status.idle":"2026-01-08T13:03:58.449315Z","shell.execute_reply.started":"2026-01-08T13:03:58.449148Z","shell.execute_reply":"2026-01-08T13:03:58.449162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_emb, test_labels, test_ids = extract_embeddings(\n    embed_model, test_loader, test_df, device\n)\n","metadata":{"id":"RlPRIjX8eaqo","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.450173Z","iopub.status.idle":"2026-01-08T13:03:58.450528Z","shell.execute_reply.started":"2026-01-08T13:03:58.450315Z","shell.execute_reply":"2026-01-08T13:03:58.450380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ntrain_emb = np.load('/kaggle/input/embeddings/train_embeddings.npy')\ntrain_labels = np.load('/kaggle/input/embeddings/train_labels.npy')\ntrain_ids = np.load('/kaggle/input/embeddings/train_image_ids.npy')\n\n\n# Validation set\nval_emb = np.load('/kaggle/input/embeddings/val_embeddings.npy')\nval_labels = np.load('/kaggle/input/embeddings/val_labels.npy')\nval_ids = np.load('/kaggle/input/embeddings/val_image_ids.npy')\n\n# Test set\ntest_emb = np.load('/kaggle/input/embeddings/test_embeddings.npy')\ntest_labels = np.load('/kaggle/input/embeddings/test_labels.npy')\ntest_ids = np.load('/kaggle/input/embeddings/test_image_ids.npy')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:40:08.157179Z","iopub.execute_input":"2026-01-08T13:40:08.157508Z","iopub.status.idle":"2026-01-08T13:40:14.068398Z","shell.execute_reply.started":"2026-01-08T13:40:08.157483Z","shell.execute_reply":"2026-01-08T13:40:14.067774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_emb.shape)  # (N_train, 1024)\nprint(val_emb.shape)    # (N_val, 1024)\n# print(test_emb.shape)   # (N_test, 1024)\n","metadata":{"id":"zYE4qbsbeeEi","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.452021Z","iopub.status.idle":"2026-01-08T13:03:58.452340Z","shell.execute_reply.started":"2026-01-08T13:03:58.452189Z","shell.execute_reply":"2026-01-08T13:03:58.452205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save(\"train_embeddings.npy\", train_emb)\nnp.save(\"val_embeddings.npy\", val_emb)\nnp.save(\"test_embeddings.npy\", test_emb)\n\nnp.save(\"train_labels.npy\", train_labels)\nnp.save(\"val_labels.npy\", val_labels)\nnp.save(\"test_labels.npy\", test_labels)\n\nnp.save(\"train_image_ids.npy\", train_ids)\nnp.save(\"val_image_ids.npy\", val_ids)\nnp.save(\"test_image_ids.npy\", test_ids)\n","metadata":{"id":"8pipRgvfeg_c","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.453481Z","iopub.status.idle":"2026-01-08T13:03:58.453733Z","shell.execute_reply.started":"2026-01-08T13:03:58.453614Z","shell.execute_reply":"2026-01-08T13:03:58.453627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path_bbox=\"/kaggle/input/data/BBox_List_2017.csv\"\nbbox_pd=pd.read_csv(path_bbox)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:40:14.069344Z","iopub.execute_input":"2026-01-08T13:40:14.069619Z","iopub.status.idle":"2026-01-08T13:40:14.079811Z","shell.execute_reply.started":"2026-01-08T13:40:14.069592Z","shell.execute_reply":"2026-01-08T13:40:14.078902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbox_pd.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:40:16.277912Z","iopub.execute_input":"2026-01-08T13:40:16.278204Z","iopub.status.idle":"2026-01-08T13:40:16.291228Z","shell.execute_reply.started":"2026-01-08T13:40:16.278180Z","shell.execute_reply":"2026-01-08T13:40:16.290580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(bbox_pd)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.458191Z","iopub.status.idle":"2026-01-08T13:03:58.458495Z","shell.execute_reply.started":"2026-01-08T13:03:58.458355Z","shell.execute_reply":"2026-01-08T13:03:58.458367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nnp.mean(np.linalg.norm(train_emb, axis=1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.459292Z","iopub.status.idle":"2026-01-08T13:03:58.459973Z","shell.execute_reply.started":"2026-01-08T13:03:58.459794Z","shell.execute_reply":"2026-01-08T13:03:58.459809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_emb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.461243Z","iopub.status.idle":"2026-01-08T13:03:58.461501Z","shell.execute_reply.started":"2026-01-08T13:03:58.461389Z","shell.execute_reply":"2026-01-08T13:03:58.461400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\nclassifier_linear = nn.Linear(train_emb.shape[1], 14).to(device)\n# criterion_asl = AsymmetricLoss()\noptimizer_basic = torch.optim.AdamW(classifier_linear.parameters(), lr=8e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:40:23.106002Z","iopub.execute_input":"2026-01-08T13:40:23.106629Z","iopub.status.idle":"2026-01-08T13:40:23.112222Z","shell.execute_reply.started":"2026-01-08T13:40:23.106604Z","shell.execute_reply":"2026-01-08T13:40:23.111544Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Linear Probe","metadata":{}},{"cell_type":"code","source":"def extract_embeddings_aligned(model, loader, device):\n    model.eval()\n\n    all_embs = []\n    all_labels = []\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Forward backbone only\n            emb = model(images, return_embedding=True)\n\n            all_embs.append(emb.cpu())\n            all_labels.append(labels.cpu())\n\n    all_embs = torch.cat(all_embs).numpy()\n    all_labels = torch.cat(all_labels).numpy()\n\n    return all_embs, all_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:40:27.073088Z","iopub.execute_input":"2026-01-08T13:40:27.073830Z","iopub.status.idle":"2026-01-08T13:40:27.078682Z","shell.execute_reply.started":"2026-01-08T13:40:27.073804Z","shell.execute_reply":"2026-01-08T13:40:27.078025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# model = DenseNet121_new(num_classes=14)\n# model = model.to(device)\n\n# print(\"Model loaded on:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.465075Z","iopub.status.idle":"2026-01-08T13:03:58.465513Z","shell.execute_reply.started":"2026-01-08T13:03:58.465274Z","shell.execute_reply":"2026-01-08T13:03:58.465291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.466650Z","iopub.status.idle":"2026-01-08T13:03:58.467012Z","shell.execute_reply.started":"2026-01-08T13:03:58.466890Z","shell.execute_reply":"2026-01-08T13:03:58.466905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_embs = []\nall_labels = []\n\nmodel.eval()\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        # labels = labels.to(device)\n\n        # emb = model.get_embedding(images)\n\n\n        # all_embs.append(emb)\n        all_labels.append(labels)\n\n# val_emb = torch.cat(all_embs).cpu().numpy()\nval_y   = torch.cat(all_labels).cpu().numpy()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:41:19.102150Z","iopub.execute_input":"2026-01-08T13:41:19.102469Z","iopub.status.idle":"2026-01-08T13:44:33.882244Z","shell.execute_reply.started":"2026-01-08T13:41:19.102440Z","shell.execute_reply":"2026-01-08T13:44:33.881435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.468869Z","iopub.status.idle":"2026-01-08T13:03:58.469089Z","shell.execute_reply.started":"2026-01-08T13:03:58.468990Z","shell.execute_reply":"2026-01-08T13:03:58.468999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_y.dtype","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.470012Z","iopub.status.idle":"2026-01-08T13:03:58.470308Z","shell.execute_reply.started":"2026-01-08T13:03:58.470170Z","shell.execute_reply":"2026-01-08T13:03:58.470185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nX_train = torch.tensor(train_emb, dtype=torch.float32).to(device)\n# y_train = torch.tensor(train_df, dtype=torch.float32).to(device)\n\nX_val = torch.tensor(val_emb, dtype=torch.float32).to(device)\n# y_val = torch.tensor(val_df, dtype=torch.float32).to(device)\n\n\n\ny_train = torch.tensor(\n    train_df[diseases].values,\n    dtype=torch.float32\n).to(device)\n\n# y_val = torch.tensor(\n#     val_df[diseases].values,\n#     dtype=torch.float32\n# ).to(device)\n\ny_val=torch.tensor(val_y, dtype=torch.float32).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:45:40.618303Z","iopub.execute_input":"2026-01-08T13:45:40.618637Z","iopub.status.idle":"2026-01-08T13:45:40.994810Z","shell.execute_reply.started":"2026-01-08T13:45:40.618607Z","shell.execute_reply":"2026-01-08T13:45:40.994197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_val.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.472472Z","iopub.status.idle":"2026-01-08T13:03:58.472768Z","shell.execute_reply.started":"2026-01-08T13:03:58.472616Z","shell.execute_reply":"2026-01-08T13:03:58.472628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.474049Z","iopub.status.idle":"2026-01-08T13:03:58.474325Z","shell.execute_reply.started":"2026-01-08T13:03:58.474190Z","shell.execute_reply":"2026-01-08T13:03:58.474204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\nlinear_head = nn.Linear(X_train.shape[1], 14).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:45:58.198641Z","iopub.execute_input":"2026-01-08T13:45:58.198917Z","iopub.status.idle":"2026-01-08T13:45:58.204044Z","shell.execute_reply.started":"2026-01-08T13:45:58.198897Z","shell.execute_reply":"2026-01-08T13:45:58.203356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = AsymmetricLoss(gamma_pos=0, gamma_neg=4, clip=0.05)\n\noptimizer = torch.optim.AdamW(\n    linear_head.parameters(),\n    lr=1e-3,\n    weight_decay=1e-4\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:46:00.484489Z","iopub.execute_input":"2026-01-08T13:46:00.484786Z","iopub.status.idle":"2026-01-08T13:46:00.489148Z","shell.execute_reply.started":"2026-01-08T13:46:00.484764Z","shell.execute_reply":"2026-01-08T13:46:00.488451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 100\n\nfor epoch in range(EPOCHS):\n    linear_head.train()\n\n    logits = linear_head(X_train)\n    loss = criterion(logits, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 5 == 0:\n        # print(roc_auc_score(logits,y_train))\n        print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:46:03.748175Z","iopub.execute_input":"2026-01-08T13:46:03.748985Z","iopub.status.idle":"2026-01-08T13:46:04.674842Z","shell.execute_reply.started":"2026-01-08T13:46:03.748958Z","shell.execute_reply":"2026-01-08T13:46:04.673906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_emb.shape)          # (N, D)\nprint(train_df.shape)           # (N, ...)\nprint(val_emb.shape)\nprint(val_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.479272Z","iopub.status.idle":"2026-01-08T13:03:58.479605Z","shell.execute_reply.started":"2026-01-08T13:03:58.479448Z","shell.execute_reply":"2026-01-08T13:03:58.479463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_emb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.480279Z","iopub.status.idle":"2026-01-08T13:03:58.480535Z","shell.execute_reply.started":"2026-01-08T13:03:58.480432Z","shell.execute_reply":"2026-01-08T13:03:58.480442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nprint(\"Mean variance:\", np.var(train_emb))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.481162Z","iopub.status.idle":"2026-01-08T13:03:58.481427Z","shell.execute_reply.started":"2026-01-08T13:03:58.481260Z","shell.execute_reply":"2026-01-08T13:03:58.481269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(y_train.sum(dim=0))\nprint(y_train.sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.483121Z","iopub.status.idle":"2026-01-08T13:03:58.483485Z","shell.execute_reply.started":"2026-01-08T13:03:58.483291Z","shell.execute_reply":"2026-01-08T13:03:58.483303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_small = X_train[:100000]\ny_small = y_train[:100000]\n\nlinear = nn.Linear(X_small.shape[1], 14).to(device)\nopt = torch.optim.Adam(linear.parameters(), lr=5e-2)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor i in range(2000):\n    opt.zero_grad()\n    loss = criterion(linear(X_small), y_small)\n    loss.backward()\n    opt.step()\n\nwith torch.no_grad():\n    probs = torch.sigmoid(linear(X_small)).cpu().numpy()\n    aucs = [\n        roc_auc_score(y_small.cpu().numpy()[:, i], probs[:, i])\n        for i in range(14)\n    ]\n\nprint(\"Overfit mean AUC:\", np.mean(aucs))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:46:27.524383Z","iopub.execute_input":"2026-01-08T13:46:27.525040Z","iopub.status.idle":"2026-01-08T13:46:43.379543Z","shell.execute_reply.started":"2026-01-08T13:46:27.525013Z","shell.execute_reply":"2026-01-08T13:46:43.378592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nimport numpy as np\n\nlinear.eval()\nwith torch.no_grad():\n    val_logits = linear(X_val)\n    val_probs = torch.sigmoid(val_logits).cpu().numpy()\n\ny_true = y_val.cpu().numpy()\n\naucs = []\nfor i in range(14):\n    aucs.append(roc_auc_score(y_true[:, i], val_probs[:, i]))\n\nmean_auc = np.mean(aucs)\nprint(\"Linear Probe Mean AUC:\", mean_auc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:47:41.899248Z","iopub.execute_input":"2026-01-08T13:47:41.900065Z","iopub.status.idle":"2026-01-08T13:47:41.994029Z","shell.execute_reply.started":"2026-01-08T13:47:41.900039Z","shell.execute_reply":"2026-01-08T13:47:41.993383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nidx = np.random.choice(len(val_emb), size=3000, replace=False)\nemb_subset = val_emb[idx]\nlabels_subset = y_val.cpu().numpy()[idx]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:48:17.291548Z","iopub.execute_input":"2026-01-08T13:48:17.292124Z","iopub.status.idle":"2026-01-08T13:48:17.302203Z","shell.execute_reply.started":"2026-01-08T13:48:17.292099Z","shell.execute_reply":"2026-01-08T13:48:17.301553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.488908Z","iopub.status.idle":"2026-01-08T13:03:58.489176Z","shell.execute_reply.started":"2026-01-08T13:03:58.489022Z","shell.execute_reply":"2026-01-08T13:03:58.489034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"idx=np.random.choice(len(train_emb),3000,replace=False)\nemb_sub = train_emb[idx]\nlabels_sub =train_labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:48:20.295933Z","iopub.execute_input":"2026-01-08T13:48:20.296506Z","iopub.status.idle":"2026-01-08T13:48:20.306794Z","shell.execute_reply.started":"2026-01-08T13:48:20.296482Z","shell.execute_reply":"2026-01-08T13:48:20.306070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nemb_pca=PCA(n_components=50).fit_transform(emb_sub)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:48:22.168409Z","iopub.execute_input":"2026-01-08T13:48:22.168669Z","iopub.status.idle":"2026-01-08T13:48:22.501575Z","shell.execute_reply.started":"2026-01-08T13:48:22.168652Z","shell.execute_reply":"2026-01-08T13:48:22.500916Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n\ntsne = TSNE(\n    n_components=3,\n    perplexity=30,\n    init='pca',\n    learning_rate=\"auto\",\n    n_iter=1000,\n    random_state=42\n)\n\nemb_2d = tsne.fit_transform(emb_pca)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:48:24.112938Z","iopub.execute_input":"2026-01-08T13:48:24.113653Z","iopub.status.idle":"2026-01-08T13:49:48.959233Z","shell.execute_reply.started":"2026-01-08T13:48:24.113632Z","shell.execute_reply":"2026-01-08T13:49:48.958265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emb_2d.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.494632Z","iopub.status.idle":"2026-01-08T13:03:58.494870Z","shell.execute_reply.started":"2026-01-08T13:03:58.494743Z","shell.execute_reply":"2026-01-08T13:03:58.494752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport plotly.express as px\n\nfig = px.scatter_3d(\n    emb_2d, x=0, y=1, z=2,\n               # Optional: color points by a label array\n    labels={'0': 'tsne-1', '1': 'tsne-2', '2': 'tsne-3'},\n    title=\"3D t-SNE Visualization (2026)\"\n)\n\n# 3. Adjust marker size for better visibility\nfig.update_traces(marker_size=5)\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:08.379182Z","iopub.execute_input":"2026-01-08T13:50:08.379864Z","iopub.status.idle":"2026-01-08T13:50:12.070640Z","shell.execute_reply.started":"2026-01-08T13:50:08.379839Z","shell.execute_reply":"2026-01-08T13:50:12.070017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nnum_diseases = labels_subset.sum(axis=1)\n\nplt.figure(figsize=(8,6))\nplt.scatter(\n    emb_2d[:, 0],\n    emb_2d[:, 1],\n    c=num_diseases,\n    cmap='viridis',\n    s=8\n)\nplt.colorbar(label=\"Number of Diseases\")\nplt.title(\"t-SNE of Chest X-ray Embeddings\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:49:48.968461Z","iopub.status.idle":"2026-01-08T13:49:48.968694Z","shell.execute_reply.started":"2026-01-08T13:49:48.968580Z","shell.execute_reply":"2026-01-08T13:49:48.968590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pneumonia_idx = labels_subset[:, diseases.index(\"Pneumonia\")]\n\nplt.figure(figsize=(8,6))\nplt.scatter(\n    emb_2d[:,0],\n    emb_2d[:,1],\n    c=pneumonia_idx,\n    cmap='coolwarm',\n    s=8\n)\nplt.title(\"t-SNE: Pneumonia vs Others\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.499477Z","iopub.status.idle":"2026-01-08T13:03:58.499768Z","shell.execute_reply.started":"2026-01-08T13:03:58.499621Z","shell.execute_reply":"2026-01-08T13:03:58.499634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for d in [\"Pneumonia\", \"Effusion\", \"Cardiomegaly\"]:\n    idx = labels_subset[:, diseases.index(d)]\n\n    plt.figure(figsize=(6,5))\n    plt.scatter(\n        emb_2d[:,0],\n        emb_2d[:,1],\n        c=idx,\n        cmap='coolwarm',\n        s=6\n    )\n    plt.title(f\"t-SNE: {d}\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.500904Z","iopub.status.idle":"2026-01-08T13:03:58.501167Z","shell.execute_reply.started":"2026-01-08T13:03:58.501024Z","shell.execute_reply":"2026-01-08T13:03:58.501033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"normal = (labels_subset.sum(axis=1) == 0).astype(int)\n\nplt.scatter(\n    emb_2d[:,0],\n    emb_2d[:,1],\n    c=normal,\n    cmap='coolwarm',\n    s=6\n)\nplt.title(\"t-SNE: Normal vs Abnormal\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.502644Z","iopub.status.idle":"2026-01-08T13:03:58.502971Z","shell.execute_reply.started":"2026-01-08T13:03:58.502808Z","shell.execute_reply":"2026-01-08T13:03:58.502821Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Trying different losses","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\ndef make_linear_head(dim, num_classes):\n    \n    return nn.Linear(dim, num_classes).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:28.328772Z","iopub.execute_input":"2026-01-08T13:50:28.329062Z","iopub.status.idle":"2026-01-08T13:50:28.333153Z","shell.execute_reply.started":"2026-01-08T13:50:28.329040Z","shell.execute_reply":"2026-01-08T13:50:28.332365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \nclass Model_basic(torch.nn.Module):\n    def __init__(self):\n        super(Model_basic,self).__init__()\n        self.linear_1=torch.nn.Linear(1024,32)\n        self.linear_2=torch.nn.Linear(32,14)\n        self.relu=torch.nn.ReLU()\n        self.sigmoid=torch.nn.Sigmoid()\n\n    def forward(self,x):\n       x=self.linear_1(x)\n       x=self.relu(x)\n       x=self.linear_2(x)\n       x=self.sigmoid(x)\n       return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:30.429806Z","iopub.execute_input":"2026-01-08T13:50:30.430577Z","iopub.status.idle":"2026-01-08T13:50:30.435512Z","shell.execute_reply.started":"2026-01-08T13:50:30.430551Z","shell.execute_reply":"2026-01-08T13:50:30.434665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_basic=Model_basic()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:33.064286Z","iopub.execute_input":"2026-01-08T13:50:33.065099Z","iopub.status.idle":"2026-01-08T13:50:33.069253Z","shell.execute_reply.started":"2026-01-08T13:50:33.065076Z","shell.execute_reply":"2026-01-08T13:50:33.068513Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncriterion_bce = nn.BCEWithLogitsLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:35.157277Z","iopub.execute_input":"2026-01-08T13:50:35.158006Z","iopub.status.idle":"2026-01-08T13:50:35.161204Z","shell.execute_reply.started":"2026-01-08T13:50:35.157981Z","shell.execute_reply":"2026-01-08T13:50:35.160532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.509165Z","iopub.status.idle":"2026-01-08T13:03:58.509482Z","shell.execute_reply.started":"2026-01-08T13:03:58.509331Z","shell.execute_reply":"2026-01-08T13:03:58.509345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_basic_01= model_basic.to(device='cuda')\nmodel_basic_02= model_basic.to(device='cuda')\nmodel_basic_03= model_basic.to(device='cuda')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:39.433731Z","iopub.execute_input":"2026-01-08T13:50:39.434531Z","iopub.status.idle":"2026-01-08T13:50:39.438705Z","shell.execute_reply.started":"2026-01-08T13:50:39.434503Z","shell.execute_reply":"2026-01-08T13:50:39.438115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_0 = make_linear_head(X_train.shape[1], 14)\noptimizer = torch.optim.AdamW(model_basic_01.parameters(), lr=7e-3)\n\nfor epoch in range(2000):\n    optimizer.zero_grad()\n    logits = model_basic_01(X_train)\n    loss = criterion_bce(logits, y_train)\n    loss.backward()\n    optimizer.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:41.073683Z","iopub.execute_input":"2026-01-08T13:50:41.073972Z","iopub.status.idle":"2026-01-08T13:50:58.950918Z","shell.execute_reply.started":"2026-01-08T13:50:41.073950Z","shell.execute_reply":"2026-01-08T13:50:58.950107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nimport numpy as np\n\ndef eval_auc(model, X, y):\n    model.eval()\n    with torch.no_grad():\n        probs = torch.sigmoid(model(X)).cpu().numpy()\n    y_true = y.cpu().numpy()\n\n    aucs = []\n    for i in range(y_true.shape[1]):\n        if len(np.unique(y_true[:, i])) > 1:\n            aucs.append(roc_auc_score(y_true[:, i], probs[:, i]))\n    return np.mean(aucs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:58.952207Z","iopub.execute_input":"2026-01-08T13:50:58.952516Z","iopub.status.idle":"2026-01-08T13:50:58.957530Z","shell.execute_reply.started":"2026-01-08T13:50:58.952492Z","shell.execute_reply":"2026-01-08T13:50:58.956794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_auc(model_0,X_val,y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:58.958309Z","iopub.execute_input":"2026-01-08T13:50:58.958532Z","iopub.status.idle":"2026-01-08T13:50:59.319494Z","shell.execute_reply.started":"2026-01-08T13:50:58.958517Z","shell.execute_reply":"2026-01-08T13:50:59.318882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion_wbce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:59.320740Z","iopub.execute_input":"2026-01-08T13:50:59.320946Z","iopub.status.idle":"2026-01-08T13:50:59.324627Z","shell.execute_reply.started":"2026-01-08T13:50:59.320929Z","shell.execute_reply":"2026-01-08T13:50:59.323934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_1 = make_linear_head(X_train.shape[1], 14)\noptimizer = torch.optim.AdamW(model.parameters(), lr=8e-3)\n\nfor epoch in range(1500):\n    optimizer.zero_grad()\n    logits = model_1(X_train)\n    loss = criterion_wbce(logits, y_train)\n    loss.backward()\n    optimizer.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:50:59.325376Z","iopub.execute_input":"2026-01-08T13:50:59.325620Z","iopub.status.idle":"2026-01-08T13:51:11.313915Z","shell.execute_reply.started":"2026-01-08T13:50:59.325594Z","shell.execute_reply":"2026-01-08T13:51:11.313310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_auc(model_1,X_val,y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:11.314706Z","iopub.execute_input":"2026-01-08T13:51:11.314986Z","iopub.status.idle":"2026-01-08T13:51:11.721075Z","shell.execute_reply.started":"2026-01-08T13:51:11.314955Z","shell.execute_reply":"2026-01-08T13:51:11.720499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        self.bce = nn.BCEWithLogitsLoss(reduction=\"none\")\n\n    def forward(self, logits, targets):\n        bce = self.bce(logits, targets)\n        probs = torch.sigmoid(logits)\n        focal = (1 - probs) ** self.gamma\n        return (focal * bce).mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:11.721838Z","iopub.execute_input":"2026-01-08T13:51:11.722147Z","iopub.status.idle":"2026-01-08T13:51:11.727784Z","shell.execute_reply.started":"2026-01-08T13:51:11.722111Z","shell.execute_reply":"2026-01-08T13:51:11.727004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion_focal = FocalLoss(gamma=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:11.729854Z","iopub.execute_input":"2026-01-08T13:51:11.730332Z","iopub.status.idle":"2026-01-08T13:51:11.740114Z","shell.execute_reply.started":"2026-01-08T13:51:11.730299Z","shell.execute_reply":"2026-01-08T13:51:11.739362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_2 = make_linear_head(X_train.shape[1], 14)\noptimizer = torch.optim.AdamW(model.parameters(), lr=8e-3)\n\nfor epoch in range(1500):\n    optimizer.zero_grad()\n    logits = model_2(X_train)\n    loss = criterion_focal(logits, y_train)\n    loss.backward()\n    optimizer.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:11.741151Z","iopub.execute_input":"2026-01-08T13:51:11.741414Z","iopub.status.idle":"2026-01-08T13:51:22.966964Z","shell.execute_reply.started":"2026-01-08T13:51:11.741394Z","shell.execute_reply":"2026-01-08T13:51:22.966064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_auc(model_2,X_val,y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:22.967825Z","iopub.execute_input":"2026-01-08T13:51:22.968106Z","iopub.status.idle":"2026-01-08T13:51:23.301501Z","shell.execute_reply.started":"2026-01-08T13:51:22.968084Z","shell.execute_reply":"2026-01-08T13:51:23.300880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AsymmetricLoss(nn.Module):\n    def __init__(self, gamma_pos=0, gamma_neg=4, clip=0.05):\n        super().__init__()\n        self.gamma_pos = gamma_pos\n        self.gamma_neg = gamma_neg\n        self.clip = clip\n\n    def forward(self, logits, targets):\n        probs = torch.sigmoid(logits)\n\n        if self.clip > 0:\n            probs = torch.clamp(probs, self.clip, 1 - self.clip)\n\n        pos_loss = targets * torch.log(probs)\n        neg_loss = (1 - targets) * torch.log(1 - probs)\n\n        pos_weight = (1 - probs) ** self.gamma_pos\n        neg_weight = probs ** self.gamma_neg\n\n        loss = - (pos_weight * pos_loss + neg_weight * neg_loss)\n        return loss.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:23.302136Z","iopub.execute_input":"2026-01-08T13:51:23.302338Z","iopub.status.idle":"2026-01-08T13:51:23.308275Z","shell.execute_reply.started":"2026-01-08T13:51:23.302305Z","shell.execute_reply":"2026-01-08T13:51:23.307695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion_asl = AsymmetricLoss(gamma_pos=0, gamma_neg=4)\nloss_asl=criterion_asl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:23.308974Z","iopub.execute_input":"2026-01-08T13:51:23.309220Z","iopub.status.idle":"2026-01-08T13:51:23.318984Z","shell.execute_reply.started":"2026-01-08T13:51:23.309204Z","shell.execute_reply":"2026-01-08T13:51:23.318361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3 = make_linear_head(X_train.shape[1], 14)\noptimizer = torch.optim.AdamW(model.parameters(), lr=9e-3)\n\nfor epoch in range(1500):\n    optimizer.zero_grad()\n    logits = model_3(X_train)\n    loss = criterion_asl(logits, y_train)\n    loss.backward()\n    optimizer.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:23.319686Z","iopub.execute_input":"2026-01-08T13:51:23.319979Z","iopub.status.idle":"2026-01-08T13:51:34.973149Z","shell.execute_reply.started":"2026-01-08T13:51:23.319955Z","shell.execute_reply":"2026-01-08T13:51:34.972362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_auc(model_3,X_val,y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:34.974937Z","iopub.execute_input":"2026-01-08T13:51:34.975196Z","iopub.status.idle":"2026-01-08T13:51:35.228792Z","shell.execute_reply.started":"2026-01-08T13:51:34.975180Z","shell.execute_reply":"2026-01-08T13:51:35.228243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"probs_bce = torch.sigmoid(model_0(X_val)).cpu().detach().numpy()\nprobs_wbce = torch.sigmoid(model_1(X_val)).cpu().detach().numpy()\nprobs_focal = torch.sigmoid(model_2(X_val)).cpu().detach().numpy()\nprobs_asl = torch.sigmoid(model_3(X_val)).cpu().detach().numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.531002Z","iopub.status.idle":"2026-01-08T13:03:58.531458Z","shell.execute_reply.started":"2026-01-08T13:03:58.531312Z","shell.execute_reply":"2026-01-08T13:03:58.531340Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Types of losses","metadata":{}},{"cell_type":"code","source":"results = {}\n\n# Example structure\nresults[\"BCE\"] = probs_bce        # shape (N, 14)\nresults[\"WBCE\"] = probs_wbce\nresults[\"Focal\"] = probs_focal\nresults[\"ASL\"] = probs_asl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:35.229420Z","iopub.execute_input":"2026-01-08T13:51:35.229608Z","iopub.status.idle":"2026-01-08T13:51:35.319013Z","shell.execute_reply.started":"2026-01-08T13:51:35.229583Z","shell.execute_reply":"2026-01-08T13:51:35.318189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results.items()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.538830Z","iopub.status.idle":"2026-01-08T13:03:58.539097Z","shell.execute_reply.started":"2026-01-08T13:03:58.538993Z","shell.execute_reply":"2026-01-08T13:03:58.539003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\ndisease_idx = diseases.index(\"Pneumonia\")\n\nplt.figure(figsize=(7,6))\ny_val_np = y_val.cpu().numpy()   # (N, 14)\n\nfor loss_name, probs in results.items():\n    fpr, tpr, _ = roc_curve(\n        y_val_np[:, disease_idx],\n        probs[:, disease_idx]\n    )\n    roc_auc = auc(fpr, tpr)\n\n    plt.plot(fpr, tpr, label=f\"{loss_name} (AUC={roc_auc:.3f})\")\n\nplt.plot([0,1], [0,1], \"k--\", alpha=0.5)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve — Pneumonia\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.540318Z","iopub.status.idle":"2026-01-08T13:03:58.540642Z","shell.execute_reply.started":"2026-01-08T13:03:58.540481Z","shell.execute_reply":"2026-01-08T13:03:58.540496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import roc_curve, auc\n\ndef macro_roc(y_true, y_prob, num_classes=14):\n    fprs, tprs = [], []\n\n    for i in range(num_classes):\n        if len(np.unique(y_true[:, i])) < 2:\n            continue\n        fpr, tpr, _ = roc_curve(y_true[:, i], y_prob[:, i])\n        fprs.append(fpr)\n        tprs.append(tpr)\n\n    # Interpolate\n    mean_fpr = np.linspace(0, 1, 100)\n    mean_tpr = np.mean([\n        np.interp(mean_fpr, fpr, tpr)\n        for fpr, tpr in zip(fprs, tprs)\n    ], axis=0)\n\n    mean_auc = auc(mean_fpr, mean_tpr)\n    return mean_fpr, mean_tpr, mean_auc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:51:38.301812Z","iopub.execute_input":"2026-01-08T13:51:38.302562Z","iopub.status.idle":"2026-01-08T13:51:38.307716Z","shell.execute_reply.started":"2026-01-08T13:51:38.302536Z","shell.execute_reply":"2026-01-08T13:51:38.307038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(7,6))\n\nfor loss_name, probs in results.items():\n    fpr, tpr, mean_auc = macro_roc(y_val_np, probs)\n    plt.plot(fpr, tpr, label=f\"{loss_name} (Mean AUC={mean_auc:.3f})\")\n\nplt.plot([0,1], [0,1], \"k--\", alpha=0.5)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Macro-Averaged ROC (14 Diseases)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.543072Z","iopub.status.idle":"2026-01-08T13:03:58.543298Z","shell.execute_reply.started":"2026-01-08T13:03:58.543189Z","shell.execute_reply":"2026-01-08T13:03:58.543201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.545330Z","iopub.status.idle":"2026-01-08T13:03:58.545694Z","shell.execute_reply.started":"2026-01-08T13:03:58.545550Z","shell.execute_reply":"2026-01-08T13:03:58.545564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.546992Z","iopub.status.idle":"2026-01-08T13:03:58.547301Z","shell.execute_reply.started":"2026-01-08T13:03:58.547147Z","shell.execute_reply":"2026-01-08T13:03:58.547160Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.548252Z","iopub.status.idle":"2026-01-08T13:03:58.548591Z","shell.execute_reply.started":"2026-01-08T13:03:58.548434Z","shell.execute_reply":"2026-01-08T13:03:58.548449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range (20):\n    print(np.sum(train_emb[i,:],axis=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.549704Z","iopub.status.idle":"2026-01-08T13:03:58.550037Z","shell.execute_reply.started":"2026-01-08T13:03:58.549869Z","shell.execute_reply":"2026-01-08T13:03:58.549883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncriterion_supcon = SupConLossMultiLabel(temperature=0.07)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:53:32.921479Z","iopub.execute_input":"2026-01-08T13:53:32.922125Z","iopub.status.idle":"2026-01-08T13:53:32.926175Z","shell.execute_reply.started":"2026-01-08T13:53:32.922100Z","shell.execute_reply":"2026-01-08T13:53:32.925342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.553066Z","iopub.status.idle":"2026-01-08T13:03:58.553460Z","shell.execute_reply.started":"2026-01-08T13:03:58.553282Z","shell.execute_reply":"2026-01-08T13:03:58.553296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logits.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.554639Z","iopub.status.idle":"2026-01-08T13:03:58.554904Z","shell.execute_reply.started":"2026-01-08T13:03:58.554784Z","shell.execute_reply":"2026-01-08T13:03:58.554795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embeddings.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.556199Z","iopub.status.idle":"2026-01-08T13:03:58.556453Z","shell.execute_reply.started":"2026-01-08T13:03:58.556344Z","shell.execute_reply":"2026-01-08T13:03:58.556358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lambda_supcon = 0.1\ncount=0\nfor images, labels in train_loader:\n    count=count+1\n    if((count%100)==0):\n        print(count)\n    images = images.to(device)\n    labels = labels.to(device).float()\n\n    optimizer.zero_grad()\n\n    # ---- Forward ----\n    embeddings = model.get_embedding(images)   # ✅ CORRECT\n    logits = model(images)\n\n    # ---- Losses ----\n    loss_cls = criterion_asl(logits, labels)\n    loss_con = criterion_supcon(embeddings, labels)\n\n    loss = loss_cls + lambda_supcon * loss_con\n\n    # ---- Backprop ----\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n    optimizer.step()\n    scheduler.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.557276Z","iopub.status.idle":"2026-01-08T13:03:58.557510Z","shell.execute_reply.started":"2026-01-08T13:03:58.557411Z","shell.execute_reply":"2026-01-08T13:03:58.557420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.558408Z","iopub.status.idle":"2026-01-08T13:03:58.558902Z","shell.execute_reply.started":"2026-01-08T13:03:58.558759Z","shell.execute_reply":"2026-01-08T13:03:58.558774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nall_probs = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device).float()\n\n        logits = model(images)                 # (B, 14)\n        probs = torch.sigmoid(logits)          # probabilities\n\n        all_probs.append(probs.cpu())\n        all_labels.append(labels.cpu())\n\ny_prob = torch.cat(all_probs).numpy()   # (N, 14)\ny_true = torch.cat(all_labels).numpy()  # (N, 14)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:54:33.375001Z","iopub.execute_input":"2026-01-08T13:54:33.375749Z","iopub.status.idle":"2026-01-08T13:57:44.745497Z","shell.execute_reply.started":"2026-01-08T13:54:33.375725Z","shell.execute_reply":"2026-01-08T13:57:44.744440Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ndisease_aucs = {}\n\nfor i, disease in enumerate(diseases):\n    # # Some diseases may have only one class in val split\n    # if len(np.unique(y_true[:, i])) < 2:\n    #     continue\n\n    disease_aucs[disease] = roc_auc_score(\n        y_true[:, i],\n        y_prob[:, i]\n    )\n    print(disease_aucs[disease])\n# mean_auc = np.mean(list(disease_aucs.values()))\n# print(\"Mean AUROC:\", mean_auc)\n\n# disease_auc[disease]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:57:44.747141Z","iopub.execute_input":"2026-01-08T13:57:44.747403Z","iopub.status.idle":"2026-01-08T13:57:44.844086Z","shell.execute_reply.started":"2026-01-08T13:57:44.747377Z","shell.execute_reply":"2026-01-08T13:57:44.843381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# y_train: (N, 14) numpy array or torch -> convert to numpy\nY = y_train.cpu().numpy()\n\nco_occurrence = Y.T @ Y        # (14, 14)\nco_occurrence = co_occurrence / co_occurrence.max()\n\nnp.fill_diagonal(co_occurrence, 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:54:06.032578Z","iopub.execute_input":"2026-01-08T13:54:06.032880Z","iopub.status.idle":"2026-01-08T13:54:06.047578Z","shell.execute_reply.started":"2026-01-08T13:54:06.032857Z","shell.execute_reply":"2026-01-08T13:54:06.046789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.563768Z","iopub.status.idle":"2026-01-08T13:03:58.564049Z","shell.execute_reply.started":"2026-01-08T13:03:58.563894Z","shell.execute_reply":"2026-01-08T13:03:58.563906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.565219Z","iopub.status.idle":"2026-01-08T13:03:58.565595Z","shell.execute_reply.started":"2026-01-08T13:03:58.565379Z","shell.execute_reply":"2026-01-08T13:03:58.565394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prototypes = {}\n\nfor i, disease in enumerate(diseases):\n    mask = (y_train[:, i] == 1)          # shape: (N,)\n    \n    # train_emb: (N, 1024)\n    disease_embs = train_emb[mask]       # (N_d, 1024)\n    \n    prototypes[disease] = disease_embs.mean(axis=0)  # (1024,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:08:25.585136Z","iopub.execute_input":"2026-01-08T14:08:25.585830Z","iopub.status.idle":"2026-01-08T14:08:25.666451Z","shell.execute_reply.started":"2026-01-08T14:08:25.585809Z","shell.execute_reply":"2026-01-08T14:08:25.665548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb=\"/kaggle/working/train_embeddings.npy\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.567938Z","iopub.status.idle":"2026-01-08T13:03:58.568242Z","shell.execute_reply.started":"2026-01-08T13:03:58.568094Z","shell.execute_reply":"2026-01-08T13:03:58.568106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb=np.load(train_emb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.568898Z","iopub.status.idle":"2026-01-08T13:03:58.569173Z","shell.execute_reply.started":"2026-01-08T13:03:58.569011Z","shell.execute_reply":"2026-01-08T13:03:58.569025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.570358Z","iopub.status.idle":"2026-01-08T13:03:58.570599Z","shell.execute_reply.started":"2026-01-08T13:03:58.570488Z","shell.execute_reply":"2026-01-08T13:03:58.570499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train[52]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.571650Z","iopub.status.idle":"2026-01-08T13:03:58.572017Z","shell.execute_reply.started":"2026-01-08T13:03:58.571902Z","shell.execute_reply":"2026-01-08T13:03:58.571914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.573256Z","iopub.status.idle":"2026-01-08T13:03:58.573517Z","shell.execute_reply.started":"2026-01-08T13:03:58.573397Z","shell.execute_reply":"2026-01-08T13:03:58.573409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb = torch.tensor(train_emb, dtype=torch.float32).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:08:21.678080Z","iopub.execute_input":"2026-01-08T14:08:21.678402Z","iopub.status.idle":"2026-01-08T14:08:21.987184Z","shell.execute_reply.started":"2026-01-08T14:08:21.678375Z","shell.execute_reply":"2026-01-08T14:08:21.986257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(prototypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.576004Z","iopub.status.idle":"2026-01-08T13:03:58.576287Z","shell.execute_reply.started":"2026-01-08T13:03:58.576122Z","shell.execute_reply":"2026-01-08T13:03:58.576145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prototypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.579278Z","iopub.status.idle":"2026-01-08T13:03:58.579571Z","shell.execute_reply.started":"2026-01-08T13:03:58.579452Z","shell.execute_reply":"2026-01-08T13:03:58.579464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prototypes=prototypes.to_device()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.580846Z","iopub.status.idle":"2026-01-08T13:03:58.581120Z","shell.execute_reply.started":"2026-01-08T13:03:58.581003Z","shell.execute_reply":"2026-01-08T13:03:58.581016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"proto_matrix.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.581985Z","iopub.status.idle":"2026-01-08T13:03:58.582240Z","shell.execute_reply.started":"2026-01-08T13:03:58.582098Z","shell.execute_reply":"2026-01-08T13:03:58.582112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch\n\n# Use torch.as_tensor() to automatically handle NumPy types\nproto_matrix = torch.stack([torch.as_tensor(prototypes[d]) for d in diseases])\n  # (14, 1024)\n\n# Normalize\nproto_matrix = F.normalize(proto_matrix, dim=1)\n\n# Cosine similarity matrix\nproto_sim = proto_matrix @ proto_matrix.T   # (14, 14)\n\n# Zero diagonal\nproto_sim.fill_diagonal_(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:08:30.884216Z","iopub.execute_input":"2026-01-08T14:08:30.885170Z","iopub.status.idle":"2026-01-08T14:08:30.941730Z","shell.execute_reply.started":"2026-01-08T14:08:30.885142Z","shell.execute_reply":"2026-01-08T14:08:30.941160Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def meta_weight(disease, metadata):\n    w = 1.0\n\n    age = metadata.get(\"age\", None)\n    view = metadata.get(\"view\", None)\n    followup = metadata.get(\"followup\", 0)\n\n    if age is not None:\n        if disease in [\"Fibrosis\", \"Emphysema\"] and age > 60:\n            w *= 1.15\n        if disease == \"Cardiomegaly\" and age < 15:\n            w *= 0.85\n\n    if disease == \"Cardiomegaly\" and view == \"AP\":\n        w *= 0.90\n\n    if followup >= 2:\n        w *= 1.05   # temporal consistency\n\n    # 🔒 safety clamp\n    return max(0.7, min(w, 1.3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:08:58.160093Z","iopub.execute_input":"2026-01-08T14:08:58.160868Z","iopub.status.idle":"2026-01-08T14:08:58.165848Z","shell.execute_reply.started":"2026-01-08T14:08:58.160840Z","shell.execute_reply":"2026-01-08T14:08:58.165028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure both are torch tensors on the same device\nco_occurrence = torch.tensor(co_occurrence, dtype=torch.float32).to(device)\n# proto_sim is already torch on GPU\nproto_sim=torch.tensor(proto_sim, dtype=torch.float32).to(device)\nA = 0.5 * co_occurrence + 0.5 * proto_sim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:09:00.540766Z","iopub.execute_input":"2026-01-08T14:09:00.541325Z","iopub.status.idle":"2026-01-08T14:09:00.546793Z","shell.execute_reply.started":"2026-01-08T14:09:00.541288Z","shell.execute_reply":"2026-01-08T14:09:00.546030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nthreshold = 0.1\n\nedges = torch.where(A > threshold)      # (row_idx, col_idx)\nedge_index = torch.stack(edges, dim=0)  # (2, E)\nedge_index = edge_index.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:09:05.666388Z","iopub.execute_input":"2026-01-08T14:09:05.666917Z","iopub.status.idle":"2026-01-08T14:09:05.671429Z","shell.execute_reply.started":"2026-01-08T14:09:05.666894Z","shell.execute_reply":"2026-01-08T14:09:05.670621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"node_features = torch.tensor(proto_matrix, dtype=torch.float32).to(device)\n# shape: (14, 1024)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:09:24.174712Z","iopub.execute_input":"2026-01-08T14:09:24.175339Z","iopub.status.idle":"2026-01-08T14:09:24.179281Z","shell.execute_reply.started":"2026-01-08T14:09:24.175302Z","shell.execute_reply":"2026-01-08T14:09:24.178635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install torch torch-geometric\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:09:31.369082Z","iopub.execute_input":"2026-01-08T14:09:31.369807Z","iopub.status.idle":"2026-01-08T14:10:47.381066Z","shell.execute_reply.started":"2026-01-08T14:09:31.369782Z","shell.execute_reply":"2026-01-08T14:10:47.380040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass DiseaseGNN(nn.Module):\n    def __init__(self, in_dim=1024, hidden_dim=256):\n        super().__init__()\n        \n        self.gcn1 = GCNConv(in_dim, hidden_dim)\n        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n\n    def forward(self, x, edge_index):\n        x = self.gcn1(x, edge_index)\n        x = F.relu(x)\n        x = self.gcn2(x, edge_index)\n        return x   # (14, hidden_dim)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:10:47.382909Z","iopub.execute_input":"2026-01-08T14:10:47.383135Z","iopub.status.idle":"2026-01-08T14:10:49.085094Z","shell.execute_reply.started":"2026-01-08T14:10:47.383113Z","shell.execute_reply":"2026-01-08T14:10:49.084283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gnn = DiseaseGNN().to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:18:51.132892Z","iopub.execute_input":"2026-01-08T14:18:51.133586Z","iopub.status.idle":"2026-01-08T14:18:51.182102Z","shell.execute_reply.started":"2026-01-08T14:18:51.133560Z","shell.execute_reply":"2026-01-08T14:18:51.181564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# gnn with the older asl + supcon version","metadata":{}},{"cell_type":"markdown","source":"i am going to train it later","metadata":{}},{"cell_type":"code","source":"\nfor images, labels in train_loader:\n    \n    images = images.to(device)\n    labels = labels.to(device).float()\n\n    optimizer.zero_grad()\n\n    # CNN\n    embeddings = model.get_embedding(images)\n    logits_img = model(images)\n\n    # GNN\n    node_repr = gnn(node_features, edge_index)\n    logits_gnn = logits_img + logits_img @ A\n\n    # Losses\n    loss_cls = criterion_asl(logits_gnn, labels)\n    loss_con = criterion_supcon(embeddings, labels)\n\n    loss = loss_cls + lambda_supcon * loss_con\n\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n    optimizer.step()\n    scheduler.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.594750Z","iopub.status.idle":"2026-01-08T13:03:58.595088Z","shell.execute_reply.started":"2026-01-08T13:03:58.594915Z","shell.execute_reply":"2026-01-08T13:03:58.594930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata={\n    \"age\":67,\n    \"gender\": 'male',\n\"view\":'AP',\n\"followup\":4\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:20:25.862976Z","iopub.execute_input":"2026-01-08T14:20:25.863521Z","iopub.status.idle":"2026-01-08T14:20:25.867255Z","shell.execute_reply.started":"2026-01-08T14:20:25.863499Z","shell.execute_reply":"2026-01-08T14:20:25.866547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def meta_weight(disease, metadata):\n    w = 1.0\n\n    age = metadata.get(\"age\", None)\n    view = metadata.get(\"view\", None)\n    followup = metadata.get(\"followup\", 0)\n\n    if age is not None:\n        if disease in [\"Fibrosis\", \"Emphysema\"] and age > 60:\n            w *= 1.15\n        if disease == \"Cardiomegaly\" and age < 15:\n            w *= 0.85\n\n    if disease == \"Cardiomegaly\" and view == \"AP\":\n        w *= 0.90\n\n    if followup >= 2:\n        w *= 1.05   # temporal consistency\n\n    # 🔒 safety clamp\n    return max(0.7, min(w, 1.3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:20:27.919573Z","iopub.execute_input":"2026-01-08T14:20:27.920247Z","iopub.status.idle":"2026-01-08T14:20:27.924850Z","shell.execute_reply.started":"2026-01-08T14:20:27.920226Z","shell.execute_reply":"2026-01-08T14:20:27.924194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_emb=np.load('/kaggle/working/train_embeddings.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.600363Z","iopub.status.idle":"2026-01-08T13:03:58.600774Z","shell.execute_reply.started":"2026-01-08T13:03:58.600613Z","shell.execute_reply":"2026-01-08T13:03:58.600627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_emb[0,:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.601467Z","iopub.status.idle":"2026-01-08T13:03:58.601760Z","shell.execute_reply.started":"2026-01-08T13:03:58.601610Z","shell.execute_reply":"2026-01-08T13:03:58.601623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"proto_matrix.type","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.602760Z","iopub.status.idle":"2026-01-08T13:03:58.603063Z","shell.execute_reply.started":"2026-01-08T13:03:58.602912Z","shell.execute_reply":"2026-01-08T13:03:58.602926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_emb.type","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.603871Z","iopub.status.idle":"2026-01-08T13:03:58.604222Z","shell.execute_reply.started":"2026-01-08T13:03:58.604033Z","shell.execute_reply":"2026-01-08T13:03:58.604047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# import tensorflow as tf# image_score shape: (num_diseases,)\nimg_emb=train_emb[0,:]\n# img_emb=torch.from_numpy(img_emb)\n\n# image_score = torch.matmul(img_emb, proto_matrix.T).squeeze(0)\n\nimport torch\nimport numpy as np\n\n# 1. Convert NumPy to Tensor\n# img_emb_np is your existing numpy array\n# img_emb = torch.from_numpy(img_emb) \n\n# 2. Check and move to the correct device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Move both tensors to the same device (e.g., GPU)\nimg_emb = img_emb.to(device)\nproto_matrix = proto_matrix.to(device)\n\n# the embedding itself will be obtained by model\nimage_score = torch.matmul(img_emb, proto_matrix.T).squeeze(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:21:36.032695Z","iopub.execute_input":"2026-01-08T14:21:36.033497Z","iopub.status.idle":"2026-01-08T14:21:36.038823Z","shell.execute_reply.started":"2026-01-08T14:21:36.033467Z","shell.execute_reply":"2026-01-08T14:21:36.038135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_scores = torch.zeros_like(image_score)\n\nfor i, disease in enumerate(diseases):\n    w = meta_weight(disease, metadata)\n    final_scores[i] = image_score[i] * w\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:22:02.105886Z","iopub.execute_input":"2026-01-08T14:22:02.106166Z","iopub.status.idle":"2026-01-08T14:22:02.111605Z","shell.execute_reply.started":"2026-01-08T14:22:02.106145Z","shell.execute_reply":"2026-01-08T14:22:02.110881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ngnn.eval()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.612505Z","iopub.status.idle":"2026-01-08T13:03:58.612821Z","shell.execute_reply.started":"2026-01-08T13:03:58.612654Z","shell.execute_reply":"2026-01-08T13:03:58.612667Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"validation set pe auc roc calculate for new model\n\ndo it later","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nimport numpy as np\n\nall_probs = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device).float()\n\n        logits_img = model(images)\n        logits_gnn = logits_img + logits_img @ A\n\n        probs = torch.sigmoid(logits_gnn)\n\n        all_probs.append(probs.cpu())\n        all_labels.append(labels.cpu())\n\ny_prob = torch.cat(all_probs).numpy()\ny_true = torch.cat(all_labels).numpy()\n\naucs = []\nfor i in range(y_true.shape[1]):\n    if len(np.unique(y_true[:, i])) > 1:\n        aucs.append(roc_auc_score(y_true[:, i], y_prob[:, i]))\n\nprint(\"Mean AUROC (CNN + GNN):\", np.mean(aucs))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.614893Z","iopub.status.idle":"2026-01-08T13:03:58.615458Z","shell.execute_reply.started":"2026-01-08T13:03:58.615269Z","shell.execute_reply":"2026-01-08T13:03:58.615283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save({\n    \"cnn\": model.state_dict(),\n    \"gnn\": gnn.state_dict(),\n    \"A\": A\n}, \"phase1_vision_graph.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:22:20.816281Z","iopub.execute_input":"2026-01-08T14:22:20.816599Z","iopub.status.idle":"2026-01-08T14:22:20.911376Z","shell.execute_reply.started":"2026-01-08T14:22:20.816578Z","shell.execute_reply":"2026-01-08T14:22:20.910764Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"finding the new embedding and label for the train loader\n\nill do it later","metadata":{}},{"cell_type":"code","source":"all_embs = []\nall_labels = []\nc=0\nwith torch.no_grad():\n    for images, labels in train_loader:\n        c=c+1\n        if(c%500==0):\n            print(c)\n        images = images.to(device)\n        labels = labels.to(device)\n\n        emb = model.get_embedding(images)\n\n        all_embs.append(emb.cpu())\n        all_labels.append(labels.cpu())\n\ntrain_emb = torch.cat(all_embs)\ny_train  = torch.cat(all_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.618488Z","iopub.status.idle":"2026-01-08T13:03:58.618709Z","shell.execute_reply.started":"2026-01-08T13:03:58.618609Z","shell.execute_reply":"2026-01-08T13:03:58.618619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Images NaN:\", torch.isnan(images).any().item())\nprint(\"Images Inf:\", torch.isinf(images).any().item())\nprint(\"Images min/max:\", images.min().item(), images.max().item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.619868Z","iopub.status.idle":"2026-01-08T13:03:58.620141Z","shell.execute_reply.started":"2026-01-08T13:03:58.619996Z","shell.execute_reply":"2026-01-08T13:03:58.620009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ckpt = torch.load(\"/kaggle/input/nih-chest-xray/pytorch/default/1/best_densenet121.pth\", map_location=device)\nmodel.load_state_dict(ckpt, strict=False)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.621034Z","iopub.status.idle":"2026-01-08T13:03:58.621234Z","shell.execute_reply.started":"2026-01-08T13:03:58.621142Z","shell.execute_reply":"2026-01-08T13:03:58.621150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    raw_feat = model.backbone.features(images)\n\nprint(\"Raw features NaN:\", torch.isnan(raw_feat).any().item())\nprint(\"Raw features Inf:\", torch.isinf(raw_feat).any().item())\nprint(\"Raw min/max:\", raw_feat.min().item(), raw_feat.max().item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.622490Z","iopub.status.idle":"2026-01-08T13:03:58.622786Z","shell.execute_reply.started":"2026-01-08T13:03:58.622634Z","shell.execute_reply":"2026-01-08T13:03:58.622646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"6 images","metadata":{}},{"cell_type":"code","source":"images.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:25:39.729195Z","iopub.execute_input":"2026-01-08T14:25:39.730031Z","iopub.status.idle":"2026-01-08T14:25:39.734796Z","shell.execute_reply.started":"2026-01-08T14:25:39.729996Z","shell.execute_reply":"2026-01-08T14:25:39.734083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n\nmodel.eval()\nwith torch.no_grad():\n    features = model.backbone.features(images)\n    features = torch.relu(features)\n\nB, C, H, W = features.shape\n\npatches = features.permute(0, 2, 3, 1).reshape(B, H*W, C)\n\n# ---- CRITICAL FIX: handle zero vectors explicitly ----\npatch_norms = torch.norm(patches, dim=-1, keepdim=True)\n\n# mask zero-norm patches\nvalid_mask = patch_norms > 1e-6\n\npatches = patches / (patch_norms + 1e-6)\npatches = patches * valid_mask  # zero out invalid patches\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.624080Z","iopub.status.idle":"2026-01-08T13:03:58.624376Z","shell.execute_reply.started":"2026-01-08T13:03:58.624231Z","shell.execute_reply":"2026-01-08T13:03:58.624242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"proto = prototypes[\"Pneumonia\"].to(device)\n\nprint(\"Proto norm:\", torch.norm(proto).item())\nprint(\"Proto NaN:\", torch.isnan(proto).any().item())\n\n# ---- CRITICAL FIX ----\nif torch.norm(proto) < 1e-6 or torch.isnan(proto).any():\n    raise ValueError(\"Prototype is invalid (zero or NaN)\")\n\nproto = proto / (torch.norm(proto) + 1e-6)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:35:52.859961Z","iopub.execute_input":"2026-01-08T14:35:52.860554Z","iopub.status.idle":"2026-01-08T14:35:52.888427Z","shell.execute_reply.started":"2026-01-08T14:35:52.860523Z","shell.execute_reply":"2026-01-08T14:35:52.887816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prototypes = {}\n\nfor i, disease in enumerate(diseases):\n    mask = (y_train[:, i] == 1)\n    prototypes[disease] = train_emb[mask].mean(dim=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:12.456598Z","iopub.execute_input":"2026-01-08T14:36:12.457195Z","iopub.status.idle":"2026-01-08T14:36:12.467241Z","shell.execute_reply.started":"2026-01-08T14:36:12.457174Z","shell.execute_reply":"2026-01-08T14:36:12.466608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with torch.no_grad():\n#     features = model.backbone.features(images)\n#     features = torch.relu(features)\nmodel.eval()\nwith torch.no_grad():\n    features = model.backbone.features(images)\n    features = torch.relu(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:18.724115Z","iopub.execute_input":"2026-01-08T14:36:18.724860Z","iopub.status.idle":"2026-01-08T14:36:18.752537Z","shell.execute_reply.started":"2026-01-08T14:36:18.724834Z","shell.execute_reply":"2026-01-08T14:36:18.751877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"B, C, H, W = features.shape\npatches = features.permute(0, 2, 3, 1).reshape(B, H*W, C)\npatches = torch.nn.functional.normalize(patches, dim=-1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:27.149424Z","iopub.execute_input":"2026-01-08T14:36:27.150130Z","iopub.status.idle":"2026-01-08T14:36:27.154413Z","shell.execute_reply.started":"2026-01-08T14:36:27.150109Z","shell.execute_reply":"2026-01-08T14:36:27.153666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"proto = torch.nn.functional.normalize(\n    prototypes[\"Pneumonia\"].to(device), dim=0\n)\n\nheatmap = (patches[0] @ proto).reshape(H, W)\nheatmap = torch.nn.functional.interpolate(\n    heatmap.unsqueeze(0).unsqueeze(0),\n    size=(224,224),\n    mode=\"bilinear\",\n    align_corners=False\n).squeeze()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:32.451179Z","iopub.execute_input":"2026-01-08T14:36:32.451924Z","iopub.status.idle":"2026-01-08T14:36:32.472088Z","shell.execute_reply.started":"2026-01-08T14:36:32.451901Z","shell.execute_reply":"2026-01-08T14:36:32.471354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(images[0].cpu().permute(1,2,0), cmap=\"gray\")\nplt.imshow(heatmap.cpu(), alpha=0.5, cmap=\"jet\")\nplt.title(\"Pneumonia localization\")\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:38.505049Z","iopub.execute_input":"2026-01-08T14:36:38.505393Z","iopub.status.idle":"2026-01-08T14:36:38.675374Z","shell.execute_reply.started":"2026-01-08T14:36:38.505364Z","shell.execute_reply":"2026-01-08T14:36:38.674654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Feature map stats:\")\nprint(\"min:\", features.min().item())\nprint(\"max:\", features.max().item())\nprint(\"mean:\", features.mean().item())\nprint(\"NaNs:\", torch.isnan(features).any())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.633937Z","iopub.status.idle":"2026-01-08T13:03:58.634373Z","shell.execute_reply.started":"2026-01-08T13:03:58.634177Z","shell.execute_reply":"2026-01-08T13:03:58.634192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Heatmap min:\", heatmap.min().item())\nprint(\"Heatmap max:\", heatmap.max().item())\nprint(\"Heatmap mean:\", heatmap.mean().item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.635438Z","iopub.status.idle":"2026-01-08T13:03:58.635756Z","shell.execute_reply.started":"2026-01-08T13:03:58.635597Z","shell.execute_reply":"2026-01-08T13:03:58.635612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"graph = {\n    \"diseases\": {},   # disease nodes\n    \"images\": {},     # image nodes\n    \"patches\": {},    # patch nodes\n    \"edges\": []       # all relations\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:46.316144Z","iopub.execute_input":"2026-01-08T14:36:46.316479Z","iopub.status.idle":"2026-01-08T14:36:46.320418Z","shell.execute_reply.started":"2026-01-08T14:36:46.316456Z","shell.execute_reply":"2026-01-08T14:36:46.319654Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# making the disease node and storing their embeddings as the value","metadata":{}},{"cell_type":"code","source":"import torch\n\nfor i, d in enumerate(diseases):\n    graph[\"diseases\"][d] = {\n        \"id\": f\"disease::{d}\",\n        \"embedding\": proto_matrix[i].cpu(),   # (1024,)\n        \"index\": i,\n        \"type\": \"disease\"\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:50.005031Z","iopub.execute_input":"2026-01-08T14:36:50.005387Z","iopub.status.idle":"2026-01-08T14:36:50.011037Z","shell.execute_reply.started":"2026-01-08T14:36:50.005361Z","shell.execute_reply":"2026-01-08T14:36:50.010271Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Images node","metadata":{}},{"cell_type":"code","source":"for i in range(images.size(0)):\n    img_key = f\"image::{image_id}\"\n\n    graph[\"images\"][img_key] = {\n        \"id\": img_key,\n        \"embedding\": emb[i].cpu(),\n        \"type\": \"image\"\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:36:57.016584Z","iopub.execute_input":"2026-01-08T14:36:57.017385Z","iopub.status.idle":"2026-01-08T14:36:57.034496Z","shell.execute_reply.started":"2026-01-08T14:36:57.017359Z","shell.execute_reply":"2026-01-08T14:36:57.033585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# disease to disease edges","metadata":{}},{"cell_type":"code","source":"threshold = 0.2   # tune later\n\nfor i, d1 in enumerate(diseases):\n    for j, d2 in enumerate(diseases):\n        if i != j and A[i, j] > threshold:\n            graph[\"edges\"].append({\n                \"src\": f\"disease::{d1}\",\n                \"dst\": f\"disease::{d2}\",\n                \"weight\": float(A[i, j].item()),\n                \"type\": \"disease_relation\"\n            })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:37:06.630940Z","iopub.execute_input":"2026-01-08T14:37:06.631235Z","iopub.status.idle":"2026-01-08T14:37:06.647643Z","shell.execute_reply.started":"2026-01-08T14:37:06.631212Z","shell.execute_reply":"2026-01-08T14:37:06.646815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# image to disease edge","metadata":{}},{"cell_type":"code","source":"            for d_idx, d in enumerate(diseases):\n                conf = probs[i, d_idx].item()\n                if conf > 0.5:\n                    graph[\"edges\"].append({\n                        \"src\": img_key,\n                        \"dst\": f\"disease::{d}\",\n                        \"weight\": conf,\n                        \"type\": \"image_prediction\"\n                    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.643107Z","iopub.status.idle":"2026-01-08T13:03:58.643462Z","shell.execute_reply.started":"2026-01-08T13:03:58.643334Z","shell.execute_reply":"2026-01-08T13:03:58.643348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"image node+image->disease edges","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nimage_id = 0\nmodel.eval()\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n\n        emb = model.get_embedding(images)     # (B, 1024)\n        logits = model(images)                # (B, D)\n        probs = torch.sigmoid(logits)\n\n        for i in range(images.size(0)):\n            img_key = f\"image::{image_id}\"\n\n            graph[\"images\"][img_key] = {\n                \"id\": img_key,\n                \"embedding\": emb[i].cpu(),\n                \"type\": \"image\"\n            }\n\n            # image → disease edges\n            for d_idx, d in enumerate(diseases):\n                conf = probs[i, d_idx].item()\n                if conf > 0.5:\n                    graph[\"edges\"].append({\n                        \"src\": img_key,\n                        \"dst\": f\"disease::{d}\",\n                        \"weight\": conf,\n                        \"type\": \"image_prediction\"\n                    })\n\n            image_id += 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T14:37:12.559435Z","iopub.execute_input":"2026-01-08T14:37:12.560052Z","iopub.status.idle":"2026-01-08T14:40:39.944532Z","shell.execute_reply.started":"2026-01-08T14:37:12.560026Z","shell.execute_reply":"2026-01-08T14:40:39.943514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# here patches are basically in form of embeddings so they can directly be used without convoluting them on model","metadata":{}},{"cell_type":"code","source":"patch_id = 0\nTOP_K = 2   # number of patches per disease per image\nq=0\nwith torch.no_grad():\n    for images, _ in val_loader:\n        images = images.to(device)\n        q=q+1\n        if (q%100==0):\n            print(q)\n        # feature map\n        features = model.backbone.features(images)\n        features = torch.relu(features)\n\n        B, C, H, W = features.shape\n    \n        patches = features.permute(0,2,3,1).reshape(B, H*W, C)\n        patches = patches / (torch.norm(patches, dim=-1, keepdim=True) + 1e-6)\n\n        # similarity: (B, D, HW)\n        sim = torch.einsum(\"bhc,dc->bdh\", patches, proto_matrix.to(device))\n\n        for b in range(B):\n            img_key = f\"image::{patch_id // (TOP_K * len(diseases))}\"\n\n            for d_idx, d in enumerate(diseases):\n                vals, idxs = torch.topk(sim[b, d_idx], TOP_K)\n\n                for score, idx in zip(vals, idxs):\n                    y = (idx // W).item()\n                    x = (idx % W).item()\n\n                    patch_key = f\"patch::{patch_id}\"\n\n                    graph[\"patches\"][patch_key] = {\n                        \"id\": patch_key,\n                        \"image\": img_key,\n                        \"location\": (x, y),\n                        \"score\": float(score.item()),\n                        \"disease\": d,\n                        \"type\": \"patch\"\n                    }\n\n                    # patch → disease\n                    graph[\"edges\"].append({\n                        \"src\": patch_key,\n                        \"dst\": f\"disease::{d}\",\n                        \"weight\": float(score.item()),\n                        \"type\": \"visual_evidence\"\n                    })\n\n                    # patch → image\n                    graph[\"edges\"].append({\n                        \"src\": patch_key,\n                        \"dst\": img_key,\n                        \"weight\": 1.0,\n                        \"type\": \"grounded_in\"\n                    })\n\n                    patch_id += 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:09:50.257872Z","iopub.execute_input":"2026-01-08T15:09:50.258481Z","iopub.status.idle":"2026-01-08T15:13:22.055993Z","shell.execute_reply.started":"2026-01-08T15:09:50.258459Z","shell.execute_reply":"2026-01-08T15:13:22.055355Z"}},"outputs":[{"name":"stdout","text":"100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n","output_type":"stream"}],"execution_count":193},{"cell_type":"code","source":"import pickle\n\nwith open(\"graph_rag_index.pkl\", \"wb\") as f:\n    pickle.dump(graph, f)\n\nprint(\"✅ Graph-RAG index saved\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:13:25.970508Z","iopub.execute_input":"2026-01-08T15:13:25.970737Z","iopub.status.idle":"2026-01-08T15:13:29.694922Z","shell.execute_reply.started":"2026-01-08T15:13:25.970715Z","shell.execute_reply":"2026-01-08T15:13:29.694060Z"}},"outputs":[{"name":"stdout","text":"✅ Graph-RAG index saved\n","output_type":"stream"}],"execution_count":195},{"cell_type":"code","source":"eps = 1e-8\nimage_scores = (image_score - image_score.min()) / (image_score.max() - image_score.min() + eps)\nfinal_score = (final_scores - final_scores.min()) / (final_scores.max() - final_scores.min() + eps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:13:29.696893Z","iopub.execute_input":"2026-01-08T15:13:29.697159Z","iopub.status.idle":"2026-01-08T15:13:29.701730Z","shell.execute_reply.started":"2026-01-08T15:13:29.697143Z","shell.execute_reply":"2026-01-08T15:13:29.701138Z"}},"outputs":[],"execution_count":196},{"cell_type":"code","source":"THRESH = 0.6\nK = 3\n\n\nselected = [\n    (diseases[i], final_score[i])\n    for i in range(len(diseases))\n    if final_score[i] >= THRESH\n]\n\nif len(selected) == 0:\n    # fallback to top-K\n    values, indices = torch.topk(final_score, k=K)\n    selected = [(diseases[i], values[j]) for j, i in enumerate(indices)]\n\npredicted_diseases = selected\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:13:29.702350Z","iopub.execute_input":"2026-01-08T15:13:29.702544Z","iopub.status.idle":"2026-01-08T15:13:29.715729Z","shell.execute_reply.started":"2026-01-08T15:13:29.702514Z","shell.execute_reply":"2026-01-08T15:13:29.715177Z"}},"outputs":[],"execution_count":197},{"cell_type":"code","source":"def get_disease_node(graph, disease):\n    return graph[\"diseases\"].get(disease)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:13:29.716405Z","iopub.execute_input":"2026-01-08T15:13:29.716631Z","iopub.status.idle":"2026-01-08T15:13:29.726051Z","shell.execute_reply.started":"2026-01-08T15:13:29.716601Z","shell.execute_reply":"2026-01-08T15:13:29.725333Z"}},"outputs":[],"execution_count":198},{"cell_type":"code","source":"def get_related_diseases(graph, disease, top_k=5):\n    src = f\"disease::{disease}\"\n    \n    rels = []\n    for e in graph[\"edges\"]:\n        if e[\"type\"] == \"disease_relation\" and e[\"src\"] == src:\n            rels.append((e[\"dst\"], e[\"weight\"]))\n    \n    rels = sorted(rels, key=lambda x: x[1], reverse=True)\n    return rels[:top_k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:13:29.726686Z","iopub.execute_input":"2026-01-08T15:13:29.726849Z","iopub.status.idle":"2026-01-08T15:13:29.734027Z","shell.execute_reply.started":"2026-01-08T15:13:29.726836Z","shell.execute_reply":"2026-01-08T15:13:29.733087Z"}},"outputs":[],"execution_count":199},{"cell_type":"code","source":"def get_supporting_images(graph, disease, min_conf=0.5, top_k=5):\n    dst = f\"disease::{disease}\"\n    \n    imgs = []\n    for e in graph[\"edges\"]:\n        if e[\"type\"] == \"image_prediction\" and e[\"dst\"] == dst:\n            imgs.append((e[\"src\"], e[\"weight\"]))\n    \n    imgs = sorted(imgs, key=lambda x: x[1], reverse=True)\n    return imgs[:top_k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:13:29.734852Z","iopub.execute_input":"2026-01-08T15:13:29.735118Z","iopub.status.idle":"2026-01-08T15:13:29.746922Z","shell.execute_reply.started":"2026-01-08T15:13:29.735086Z","shell.execute_reply":"2026-01-08T15:13:29.746373Z"}},"outputs":[],"execution_count":200},{"cell_type":"code","source":"def get_visual_evidence(graph, disease, top_k=5):\n    evidences = []\n    \n    for patch_id, patch in graph[\"patches\"].items():\n        if patch[\"disease\"] == disease:\n            evidences.append((\n                patch_id,\n                patch[\"image\"],\n                patch[\"location\"],\n                patch[\"score\"]\n            ))\n    \n    evidences = sorted(evidences, key=lambda x: x[3], reverse=True)\n    return evidences[:top_k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:13:29.747642Z","iopub.execute_input":"2026-01-08T15:13:29.747824Z","iopub.status.idle":"2026-01-08T15:13:29.758004Z","shell.execute_reply.started":"2026-01-08T15:13:29.747810Z","shell.execute_reply":"2026-01-08T15:13:29.757415Z"}},"outputs":[],"execution_count":201},{"cell_type":"code","source":"def retrieve_for_reasoning(\n    graph,\n    disease,\n    image_score,\n    final_score,\n    metadata,\n    score_adjustments\n):\n    return {\n        \"disease\": disease,\n\n        # 🔹 Scores (SAFE scalar extraction)\n        \"image_score\":  [t.numpy(force=True) for t in image_score],\n        \"final_score\":  [t.numpy(force=True) for t in final_score],\n        \"score_adjustments\": score_adjustments,\n\n        # 🔹 Metadata\n        \"metadata\": metadata,\n\n        # 🔹 Graph retrieval\n        \"related_diseases\": get_related_diseases(graph, disease),\n        \"supporting_images\": get_supporting_images(graph, disease),\n\n        # 🔹 Visual grounding\n        \"visual_evidence\": get_visual_evidence(graph, disease)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:39:16.492584Z","iopub.execute_input":"2026-01-08T15:39:16.493101Z","iopub.status.idle":"2026-01-08T15:39:16.497879Z","shell.execute_reply.started":"2026-01-08T15:39:16.493080Z","shell.execute_reply":"2026-01-08T15:39:16.497134Z"}},"outputs":[],"execution_count":224},{"cell_type":"code","source":"def explain_meta_adjustment(disease, metadata):\n    \"\"\"\n    Returns a list of human-readable explanations\n    describing why metadata affected the confidence score\n    for a given disease.\n    \"\"\"\n\n    explanations = []\n\n    age = metadata.get(\"age\")\n    gender = metadata.get(\"gender\")\n    view = metadata.get(\"view\")\n    followup = metadata.get(\"followup\")\n\n    # ---- Age-based explanations ----\n    if age is not None:\n        if disease in [\"Fibrosis\", \"Emphysema\"] and age >= 60:\n            explanations.append(\n                \"Confidence increased due to higher prevalence of chronic lung disease in older patients.\"\n            )\n\n        if disease == \"Cardiomegaly\" and age < 15:\n            explanations.append(\n                \"Confidence reduced as cardiomegaly is less common in pediatric patients.\"\n            )\n\n    # ---- View position explanations ----\n    if view is not None:\n        if disease == \"Cardiomegaly\" and view.upper() == \"AP\":\n            explanations.append(\n                \"Confidence slightly reduced because AP view can exaggerate apparent heart size.\"\n            )\n\n    # ---- Follow-up / temporal explanations ----\n    if followup is not None:\n        if followup >= 2:\n            explanations.append(\n                \"Confidence adjusted based on consistency across multiple follow-up examinations.\"\n            )\n\n    # ---- Fallback if no metadata affected the score ----\n    if len(explanations) == 0:\n        explanations.append(\n            \"No metadata-based adjustment was applied to the confidence score.\"\n        )\n\n    return explanations\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:23:28.185183Z","iopub.execute_input":"2026-01-08T15:23:28.185936Z","iopub.status.idle":"2026-01-08T15:23:28.192521Z","shell.execute_reply.started":"2026-01-08T15:23:28.185911Z","shell.execute_reply":"2026-01-08T15:23:28.191686Z"}},"outputs":[],"execution_count":219},{"cell_type":"code","source":"# def build_llm_prompt(context):\n#     disease = context[\"disease\"]\n\n#     # -------- Metadata --------\n#     metadata = context.get(\"metadata\", {})\n#     age = metadata.get(\"age\", \"unknown\")\n#     gender = metadata.get(\"gender\", \"unknown\")\n#     view = metadata.get(\"view\", \"unknown\")\n#     followup = metadata.get(\"followup\", \"unknown\")\n\n#     # -------- Scores --------\"image_score\": image_score.item() if torch.is_tensor(image_score) else float(image_score)\n\n#     image_score = context[\"image_score\"]\n#     final_score = context[\"final_score\"]\n#     # adjustments = context.get(\"score_adjustments\", [])\n\n#     # -------- Graph --------\n#     related = \", \".join([\n#         d.replace(\"disease::\", \"\") for d, _ in context[\"related_diseases\"]\n#     ])\n\n#     images = \", \".join([\n#         img.replace(\"image::\", \"\") for img, _ in context[\"supporting_images\"]\n#     ])\n\n#     # -------- Visual evidence --------\n#     evidence_lines = []\n#     for patch_id, img, loc, score in context[\"visual_evidence\"]:\n#         evidence_lines.append(\n#             f\"- Patch at location {loc} in {img} (similarity {score:.2f})\"\n#         )\n#     evidence_text = \"\\n\".join(evidence_lines)\n#     adjustment = explain_meta_adjustment(disease, metadata)\n#     # -------- Adjustment explanation --------\n#     adjustment_text = (\n#         \"\\n\".join([f\"- {adjustment}\"])\n#         if adjustment else\n#         \"No metadata-based adjustment applied.\"\n#     )\n\n#     # -------- Prompt --------\n#     prompt = f\"\"\"\n#         You are a clinical decision support assistant for chest X-ray interpretation.\n        \n#         Patient metadata:\n#         - Age: {age}\n#         - Gender: {gender}\n#         - View: {view}\n#         - Follow-up number: {followup}\n        \n#         Disease under consideration:\n#         {disease}\n        \n#         Visual evidence summary:\n#         - Image-based similarity score: {image_score:.2f}\n#         - Metadata-adjusted confidence score: {final_score:.2f}\n        \n#         Metadata-based score adjustments:\n#         {adjustment_text}\n        \n#         Related diseases based on learned medical graph:\n#         {related}\n        \n#         Supporting images with high-confidence associations:\n#         {images}\n        \n#         Localized visual evidence supporting this finding:\n#         {evidence_text}\n        \n#         Task:\n#         Using ONLY the information above:\n#         1. Explain why {disease} is suggested by the visual evidence\n#         2. Explain how patient metadata influenced the confidence (if applicable)\n#         3. Describe how related diseases are medically connected\n#         4. Indicate whether this appears stable, improving, or uncertain given the follow-up context\n        \n#         Constraints:\n#         - Do NOT introduce new diseases\n#         - Do NOT make definitive diagnoses\n#         - Use cautious, radiology-style language\n#         - Base all reasoning on provided evidence only\n#         \"\"\"\n#     return prompt\ndef build_llm_prompt(context):\n    # ---------------- Disease ----------------\n    disease = context[\"disease\"]\n\n    # ---------------- Metadata ----------------\n    metadata = context.get(\"metadata\", {})\n    age = metadata.get(\"age\", \"unknown\")\n    gender = metadata.get(\"gender\", \"unknown\")\n    view = metadata.get(\"view\", \"unknown\")\n    followup = metadata.get(\"followup\", \"unknown\")\n\n    # ---------------- Scores ----------------\n    image_score = context[\"image_score\"]\n    final_score = context[\"final_score\"]\n\n    # ---------------- Graph ----------------\n    related = \", \".join(\n        d.replace(\"disease::\", \"\") for d, _ in context.get(\"related_diseases\", [])\n    ) or \"None\"\n\n    images = \", \".join(\n        img.replace(\"image::\", \"\") for img, _ in context.get(\"supporting_images\", [])\n    ) or \"None\"\n\n    # ---------------- Visual Evidence ----------------\n    evidence_lines = []\n    for patch_id, img, loc, score in context.get(\"visual_evidence\", []):\n        evidence_lines.append(\n            f\"- Patch at location {loc} in {img} (similarity {score:.2f})\"\n        )\n\n    evidence_text = \"\\n\".join(evidence_lines) or \"No localized visual evidence available.\"\n\n    # ---------------- Metadata Adjustment Explanation ----------------\n    adjustments = explain_meta_adjustment(disease, metadata)\n\n    if adjustments:\n        adjustment_text = \"\\n\".join(f\"- {a}\" for a in adjustments)\n    else:\n        adjustment_text = \"No metadata-based adjustment applied.\"\n\n    # ---------------- Prompt ----------------\n    prompt = f\"\"\"\nYou are a clinical decision support assistant for chest X-ray interpretation.\n\nPatient metadata:\n- Age: {age}\n- Gender: {gender}\n- View: {view}\n- Follow-up number: {followup}\n\nDisease under consideration:\n{disease}\n\nVisual evidence summary:\n- Image-based similarity score: {image_score}\n- Metadata-adjusted confidence score: {final_score}\n\nMetadata-based score adjustments:\n{adjustment_text}\n\nRelated diseases based on learned medical graph:\n{related}\n\nSupporting images with high-confidence associations:\n{images}\n\nLocalized visual evidence supporting this finding:\n{evidence_text}\n\nTask:\nUsing ONLY the information above:\n1. Explain why {disease} is suggested by the visual evidence\n2. Explain how patient metadata influenced the confidence (if applicable)\n3. Describe how related diseases are medically connected\n4. Indicate whether this appears stable, improving, or uncertain given the follow-up context\n\nConstraints:\n- Do NOT introduce new diseases\n- Do NOT make definitive diagnoses\n- Use cautious, radiology-style language\n- Base all reasoning strictly on the provided evidence\n\"\"\"\n    return prompt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:50:26.968989Z","iopub.execute_input":"2026-01-08T15:50:26.969934Z","iopub.status.idle":"2026-01-08T15:50:26.981115Z","shell.execute_reply.started":"2026-01-08T15:50:26.969901Z","shell.execute_reply":"2026-01-08T15:50:26.980334Z"}},"outputs":[],"execution_count":234},{"cell_type":"code","source":"from openai import OpenAI\n\nclient = OpenAI(api_key='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')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:19:02.058122Z","iopub.execute_input":"2026-01-08T15:19:02.058487Z","iopub.status.idle":"2026-01-08T15:19:03.500511Z","shell.execute_reply.started":"2026-01-08T15:19:02.058464Z","shell.execute_reply":"2026-01-08T15:19:03.499694Z"}},"outputs":[],"execution_count":205},{"cell_type":"code","source":"def response_ai(prompt, temprature=0.2):\n    response = client.chat.completions.create(\n    model=\"gpt-4o-mini\",   # or any model\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a medical imaging assistant.\"},\n        {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=temprature)\n\n    return (response.choices[0].message.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:19:23.501757Z","iopub.execute_input":"2026-01-08T15:19:23.502027Z","iopub.status.idle":"2026-01-08T15:19:23.506624Z","shell.execute_reply.started":"2026-01-08T15:19:23.502006Z","shell.execute_reply":"2026-01-08T15:19:23.505926Z"}},"outputs":[],"execution_count":210},{"cell_type":"code","source":"all_explanations = {}\n\nfor idx in range (len(selected)):\n    disease = predicted_diseases[idx]\n\n    context = retrieve_for_reasoning(\n        graph,\n        disease,\n        image_scores,\n        final_score,\n        metadata,\n        explain_meta_adjustment(disease, metadata)\n            )\n\n    prompt =(build_llm_prompt(context))  # this gives llm call llm each time\n    all_explanations[disease] = response_ai(prompt, temprature=0.2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:50:29.047294Z","iopub.execute_input":"2026-01-08T15:50:29.047585Z","iopub.status.idle":"2026-01-08T15:50:46.195201Z","shell.execute_reply.started":"2026-01-08T15:50:29.047566Z","shell.execute_reply":"2026-01-08T15:50:46.194572Z"}},"outputs":[],"execution_count":235},{"cell_type":"code","source":"all_explanations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T15:51:09.487757Z","iopub.execute_input":"2026-01-08T15:51:09.488423Z","iopub.status.idle":"2026-01-08T15:51:09.496064Z","shell.execute_reply.started":"2026-01-08T15:51:09.488396Z","shell.execute_reply":"2026-01-08T15:51:09.495367Z"}},"outputs":[{"execution_count":236,"output_type":"execute_result","data":{"text/plain":"{('Emphysema',\n  tensor(0.9920, device='cuda:0')): \"1. The suggestion of ('Emphysema', tensor(0.9920, device='cuda:0')) is primarily supported by the high confidence score associated with the visual evidence. The image-based similarity scores indicate a range of correlations with prior examinations, with the highest score being 0.99999994, suggesting a strong visual resemblance to previously identified cases of emphysema. This high score, combined with the metadata-adjusted confidence score of 1.0, indicates a robust association with the disease, reinforcing the likelihood of emphysema being present in this patient.\\n\\n2. Patient metadata, specifically the age (67 years) and gender (male), likely influenced the confidence scores. Older males are statistically at a higher risk for developing emphysema, which may have contributed to the adjustments made to the confidence scores based on this demographic information. The consistency across multiple follow-up examinations also plays a role in enhancing the confidence in the current interpretation, as it suggests a persistent pattern that aligns with the characteristics of emphysema.\\n\\n3. There are no related diseases identified in the provided evidence. This absence indicates that the analysis is focused solely on emphysema without any direct associations to other conditions, which could suggest a more isolated evaluation of the patient's lung health in this context.\\n\\n4. Given the follow-up context, the findings appear stable. The high confidence scores, particularly the metadata-adjusted score of 1.0, suggest that there has been consistency in the imaging findings across follow-ups. However, without localized visual evidence or indications of improvement or deterioration, the overall assessment remains cautious and indicates stability rather than clear improvement or worsening.\",\n ('Fibrosis',\n  tensor(1., device='cuda:0')): \"1. The suggestion of fibrosis is supported by the visual evidence, particularly indicated by the high image-based similarity scores, with the highest score reaching approximately 0.99999994. This suggests a strong correlation with features typically associated with fibrosis on chest X-rays. The presence of multiple scores above 0.6 further reinforces the likelihood of this finding, indicating that the visual characteristics observed in the current examination may resemble those seen in previous cases of fibrosis.\\n\\n2. The patient metadata, including age and gender, likely influenced the confidence scores, particularly given the patient's age of 67, which is a demographic more prone to pulmonary conditions such as fibrosis. The metadata-adjusted confidence scores reflect a systematic approach to evaluating the consistency of findings across multiple follow-up examinations. The highest confidence scores (around 1.0) suggest that the findings are consistent with previous evaluations, thereby enhancing the overall confidence in the interpretation.\\n\\n3. There are no related diseases indicated in the provided evidence. The absence of related diseases suggests that the focus remains solely on the consideration of fibrosis without complicating factors or differential diagnoses that might typically arise in a clinical context.\\n\\n4. Given the follow-up context, the findings appear to be stable. The consistency across multiple follow-up examinations, as indicated by the metadata-adjusted confidence scores, suggests that there has not been significant progression or regression in the condition. However, without localized visual evidence or additional clinical context, the overall assessment remains cautious and acknowledges the uncertainty inherent in interpreting imaging findings over time.\"}"},"metadata":{}}],"execution_count":236},{"cell_type":"code","source":"from openai import OpenAI\n\nclient = OpenAI(api_key='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')\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",   # or any model\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a medical imaging assistant.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ],\n    temperature=0.2\n)\n\nprint(response.choices[0].message.content)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.667118Z","iopub.status.idle":"2026-01-08T13:03:58.667380Z","shell.execute_reply.started":"2026-01-08T13:03:58.667252Z","shell.execute_reply":"2026-01-08T13:03:58.667262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context = retrieve_for_reasoning(graph, \"Pneumonia\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.659510Z","iopub.status.idle":"2026-01-08T13:03:58.659802Z","shell.execute_reply.started":"2026-01-08T13:03:58.659650Z","shell.execute_reply":"2026-01-08T13:03:58.659663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.660787Z","iopub.status.idle":"2026-01-08T13:03:58.661113Z","shell.execute_reply.started":"2026-01-08T13:03:58.660947Z","shell.execute_reply":"2026-01-08T13:03:58.660963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = build_llm_prompt(context)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.662153Z","iopub.status.idle":"2026-01-08T13:03:58.662477Z","shell.execute_reply.started":"2026-01-08T13:03:58.662304Z","shell.execute_reply":"2026-01-08T13:03:58.662335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"OPENAI_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.663099Z","iopub.status.idle":"2026-01-08T13:03:58.663412Z","shell.execute_reply.started":"2026-01-08T13:03:58.663234Z","shell.execute_reply":"2026-01-08T13:03:58.663248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"secret_value_0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.665619Z","iopub.status.idle":"2026-01-08T13:03:58.665928Z","shell.execute_reply.started":"2026-01-08T13:03:58.665755Z","shell.execute_reply":"2026-01-08T13:03:58.665770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.668487Z","iopub.status.idle":"2026-01-08T13:03:58.668782Z","shell.execute_reply.started":"2026-01-08T13:03:58.668632Z","shell.execute_reply":"2026-01-08T13:03:58.668646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.670232Z","iopub.status.idle":"2026-01-08T13:03:58.670473Z","shell.execute_reply.started":"2026-01-08T13:03:58.670370Z","shell.execute_reply":"2026-01-08T13:03:58.670380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ckpt = torch.load(\"/kaggle/working/phase1_vision_graph.pth\", map_location=device)\n\nmodel.load_state_dict(ckpt[\"cnn\"])\nmodel.eval()\n\nproto_matrix = ckpt[\"proto_matrix\"].to(device)\nA = ckpt[\"adjacency\"].to(device)\ndiseases = ckpt[\"diseases\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T13:03:58.671693Z","iopub.status.idle":"2026-01-08T13:03:58.671974Z","shell.execute_reply.started":"2026-01-08T13:03:58.671795Z","shell.execute_reply":"2026-01-08T13:03:58.671809Z"}},"outputs":[],"execution_count":null}]}