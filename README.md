# ğŸ©º Graph-Augmented Medical Diagnosis from Chest X-rays

A research-oriented medical AI system that combines deep visual representation learning, disease knowledge graphs, and graph-based reasoning to perform robust and interpretable chest X-ray diagnosis.

# ğŸ“Œ Overview

Chest X-ray interpretation is a core clinical task, but purely image-based deep learning models often ignore structured relationships between diseases (e.g., co-occurrence, clinical dependencies).

This project proposes a multi-stage pipeline that integrates:

CNN-based visual learning (DenseNet-121)

Patient-wise evaluation to prevent data leakage

Disease co-occurrence knowledge graphs

Graph Neural Networks (GNNs)

(Planned) Graph-RAG style reasoning and explanations

The result is a context-aware, interpretable, and research-grade medical AI system.

# ğŸ¯ Key Contributions

âœ” Patient-level train/validation/test splitting (no leakage)

âœ” Strong CNN baseline trained on large-scale chest X-ray data

âœ” Extraction of deep image embeddings (not just predictions)

âœ” Construction of a disease knowledge graph from data

âœ” Semantic node features using biomedical language models

âœ” Foundation for CNN + GNN fusion and Graph-RAG reasoning



# ğŸ§  Methodology (High-Level)

Chest X-ray Image
        â†“
CNN (DenseNet-121)
        â†“
Image Embeddings (1024-D)
        â†“
Disease Probability Predictions
        â†“
Disease Knowledge Graph (Co-occurrence + Semantics)
        â†“
Graph Neural Network (GNN)
        â†“
Refined Predictions + Explainable Reasoning



# ğŸ“‚ Dataset

NIH ChestX-ray14 Dataset

112,120 frontal chest X-ray images

14 thoracic disease labels

Multi-label classification setting

Real clinical data from NIH Clinical Center

# Labels
Atelectasis, Cardiomegaly, Effusion, Infiltration,
Mass, Nodule, Pneumonia, Pneumothorax,
Consolidation, Edema, Emphysema, Fibrosis,
Pleural Thickening, Hernia

Important Note

All dataset splits are performed patient-wise, ensuring that no patient appears in more than one split â€” a critical requirement for medical AI research.

âš™ï¸ Project Structure
â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ train_patient_split.csv

â”‚   â”œâ”€â”€ val_patient_split.csv

â”‚   â””â”€â”€ test_patient_split.csv

â”‚

â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ densenet121.py

â”‚   â””â”€â”€ gnn_models.py

â”‚

â”œâ”€â”€ embeddings/

â”‚   â”œâ”€â”€ train_embeddings.npy

â”‚   â”œâ”€â”€ val_embeddings.npy

â”‚   â””â”€â”€ test_embeddings.npy

â”‚

â”œâ”€â”€ graph/

â”‚   â”œâ”€â”€ nodes.csv

â”‚   â”œâ”€â”€ edges.csv

â”‚   â””â”€â”€ node_embeddings.npy

â”‚

â”œâ”€â”€ notebooks/

â”‚   â”œâ”€â”€ phase1_data_analysis.ipynb

â”‚   â”œâ”€â”€ phase2_cnn_training.ipynb

â”‚   â””â”€â”€ phase3_graph_construction.ipynb

â”‚

â””â”€â”€ README.md



# ğŸ”¬ Phase-wise Breakdown

Phase 1 â€” Data Analysis & Preparation

Dataset exploration and cleaning

Multi-hot label encoding

Patient-wise splitting

Class imbalance analysis



Phase 2 â€” Deep Visual Modeling

DenseNet-121 (ImageNet-pretrained)

Multi-label classification with BCEWithLogitsLoss

Class imbalance handling via positive class weights

AUROC-based evaluation

Extraction of deep image embeddings



Phase 3 â€” Knowledge Graph Construction

Disease co-occurrence matrix from training data

Graph construction (nodes + weighted edges)

Semantic node features using BioBERT-based embeddings



Phase 4  â€” Graph Neural Networks

GraphSAGE / GAT over disease graph

Learning disease-level representations

Modeling label dependencies explicitly



Phase 5  â€” CNN + GNN Fusion

Fusion of image embeddings with graph embeddings

Improved prediction consistency and robustness



Phase 6 â€” Graph-RAG Reasoning

Retrieval of graph-based clinical context

Structured evidence packs for predictions

Natural-language explanations of model decisions





# ğŸ“Š Evaluation Protocol

Primary Metric: AUROC (per-class + mean)

Why AUROC: Robust to class imbalance, standard in medical imaging

No test-set exposure during training or validation



# ğŸ§ª Interpretability (Planned)

Grad-CAM visual explanations for CNN predictions

Graph-based explanation of disease co-occurrence

Combined visual + relational interpretability



# ğŸš€ How to Run (High-Level)

Download dataset (via Kaggle)

Run notebook for preprocessing

Train CNN (Phase 2)

Extract embeddings

Build disease graph (Phase 3)

Train GNN and fusion models (Phase 4â€“5)



# ğŸ“ Research Motivation

Pure CNN-based systems treat diseases as independent labels.
This project explicitly models clinical relationships between diseases, bringing the system closer to how radiologists reason.

The design aligns with research directions seen in:

MICCAI

NeurIPS (Medical AI workshops)

Clinical decision-support systems

# ğŸ“š References

Wang et al., ChestX-ray14: Hospital-scale Chest X-ray Database

Rajpurkar et al., CheXNet

Kipf & Welling, Graph Convolutional Networks

Hamilton et al., GraphSAGE


# ğŸ¤ Acknowledgements

NIH Clinical Center, open-source ML community, and prior work in medical AI that inspired this pipeline.
